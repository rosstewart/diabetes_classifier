{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef9c85cc-057f-4722-a6be-535e846845ad",
   "metadata": {},
   "source": [
    "## import packages and define cnn & helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891ef771-43c4-4bb1-b6da-e769b829c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nnF\n",
    "from torch.utils.data import DataLoader as torch_dataloader\n",
    "from torch.utils.data import Dataset as torch_dataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "2a23c3f5-b3e2-4976-9c16-8b765633f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=256, \n",
    "                               kernel_size=3, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=256, out_channels=256, \n",
    "                               kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=256, out_channels=256, \n",
    "                               kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=256, out_channels=256, \n",
    "                               kernel_size=3, stride=2, padding=2)\n",
    "        self.conv5 = nn.Conv1d(in_channels=256, out_channels=1, \n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(2, out_features=1024)\n",
    "        self.fc2 = nn.Linear(1024, 2)\n",
    "        self.norm3 = nn.BatchNorm1d(num_features=256) # 1 channel\n",
    "        self.norm4 = nn.BatchNorm1d(num_features=256)\n",
    "        self.norm5 = nn.BatchNorm1d(num_features=256)\n",
    "        self.avg1 = nn.AvgPool1d(kernel_size=2, stride=2,padding=1)\n",
    "        self.avg2 = nn.AvgPool1d(kernel_size=2, stride=2,padding=1)\n",
    "        self.avg3 = nn.AvgPool1d(kernel_size=2, stride=2,padding=1)\n",
    "    def forward(self, x):\n",
    "        x=nnF.relu(self.conv1(x))\n",
    "        x1 = self.avg1(x)\n",
    "        # print(nnF.relu(self.conv2(x)).shape,x1.shape)\n",
    "        x=nnF.relu(self.conv2(x)) + x1 # residual connection\n",
    "        x1 = self.avg2(x)\n",
    "        # print(nnF.relu(self.conv3(self.norm3(x))).shape,x1.shape)\n",
    "        x=nnF.relu(self.conv3(self.norm3(x))) + x1\n",
    "        x1 = self.avg3(x)\n",
    "#         print(nnF.relu(self.conv4(x)).shape,x1.shape)\n",
    "        x=nnF.relu(self.conv4(self.norm4(x))) + x1\n",
    "        # print(nnF.relu(self.conv5(self.norm5(x))).shape)\n",
    "        x=nnF.relu(self.conv5(self.norm5(x))).squeeze(1)\n",
    "        # print(x.shape)\n",
    "        x=nnF.relu(self.fc1(x))\n",
    "        z=self.fc2(x)\n",
    "        #y=nnF.softmax(z, dim=1)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98dcae-e8a5-4fee-91ec-c4f88b53aeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3a2b1859-35c2-41a7-af77-ea172842ddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(confusion):\n",
    "    #input: confusion is the confusion matrix\n",
    "    #output: acc is the standard classification accuracy\n",
    "    M=confusion.copy().astype('float32')\n",
    "    acc = M.diagonal().sum()/M.sum()    \n",
    "    sens=np.zeros(M.shape[0])\n",
    "    prec=np.zeros(M.shape[0]) \n",
    "    for n in range(0, M.shape[0]):\n",
    "        TP=M[n,n]\n",
    "        FN=np.sum(M[n,:])-TP\n",
    "        FP=np.sum(M[:,n])-TP\n",
    "        sens[n]=TP/(TP+FN)\n",
    "        prec[n]=TP/(TP+FP)       \n",
    "    return acc, sens, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e54ceda-3731-4de5-b692-bf40ed747a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, optimizer, dataloader, epoch):    \n",
    "    model.train()#set model to training mode\n",
    "    loss_train=0\n",
    "    acc_train =0 \n",
    "    sample_count=0\n",
    "    for batch_idx, (X, Y) in enumerate(dataloader):\n",
    "#         print(X.shape)\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()#clear grad of each parameter\n",
    "        Z = model(X)#forward pass\n",
    "#         print(Z.shape, Y.shape)\n",
    "        loss = nnF.cross_entropy(Z, Y)\n",
    "        loss.backward()#backward pass\n",
    "        optimizer.step()#update parameters\n",
    "        loss_train+=loss.item()\n",
    "        #do not need softmax\n",
    "        Yp = Z.data.max(dim=1)[1]  # get the index of the max               \n",
    "        acc_train+= torch.sum(Yp==Y).item()\n",
    "        sample_count+=X.size(0)\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{:.0f}%]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, 100. * batch_idx / len(dataloader), loss.item()))\n",
    "    loss_train/=len(dataloader)\n",
    "    #acc_train/=len(dataloader.dataset) \n",
    "    acc_train/=sample_count    \n",
    "    return loss_train, acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d60847-571d-4047-9068-48cd206695a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, dataloader):\n",
    "    Ys, Yps = [],[]\n",
    "    model.eval()#set model to evaluation mode\n",
    "    acc_test =0\n",
    "    confusion=np.zeros((2,2))\n",
    "    with torch.no_grad(): # tell Pytorch not to build graph in the with section\n",
    "        for batch_idx, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "#             print(X.shape)\n",
    "            Z = model(X)#forward pass\n",
    "            #do not need softmax\n",
    "            Yp = Z.data.max(dim=1)[1]  # get the index of the max \n",
    "            Ys.extend(Y)\n",
    "            Yps.extend(Yp)\n",
    "            acc_test+= torch.sum(Yp==Y).item()\n",
    "            for i in range(0, 2):\n",
    "                for j in range(0, 2):\n",
    "                    confusion[i,j]+=torch.sum((Y==i)&(Yp==j)).item()\n",
    "    acc, sens, prec=cal_accuracy(confusion)\n",
    "    return acc, (confusion, sens, prec), Ys, Yps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149a636c-8bfa-4912-9eea-dedc0e3b5d82",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9d9414-97ae-49f2-8049-6fa79b5b67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8dba7-ae0e-4ecd-9682-1c263eb20212",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_include = \"preg\tplasma\tpressure\tskin\tinsulin\tbmi\tpedigree\tage\".split()\n",
    "X = data[cols_to_include].values\n",
    "Y = data[\"class\"].values\n",
    "\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler.fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(Y), y=Y)\n",
    "# class_weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379f165-ae9d-47ec-9f6f-74a6ec662f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cols_to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f2e8c3-50f6-4648-89af-4cb3e1cf58b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf5784d-a732-4eeb-a2eb-f8097ea118cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch_dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X=X\n",
    "        self.Y=Y\n",
    "    def __len__(self):\n",
    "        #return the number of data points\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):        \n",
    "        #we can use DatasetName[idx] to get a data point (x,y) with index idx\n",
    "        x=torch.tensor(self.X[idx], dtype=torch.float32)\n",
    "        y=torch.tensor(self.Y[idx], dtype=torch.int64)\n",
    "        x=x.reshape(1,-1)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed944cc-35f3-4f43-96e3-9152f989c569",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "dataset_train=MyDataset(X_train, Y_train)\n",
    "dataset_val=MyDataset(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d325bb56-86f8-4908-b74f-b8a772cf072b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_train = torch_dataloader(dataset_train, batch_size=4, shuffle=True, num_workers=0)\n",
    "loader_val = torch_dataloader(dataset_val, batch_size=4, shuffle=False, num_workers=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863be9d6-722b-4f5d-bad3-4f3a21091b66",
   "metadata": {},
   "source": [
    "## initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293b0f0-892a-4695-95bb-fcfadc0d36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=Net()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2372a56-c39f-475a-a81b-ec3ae0a82652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c184e7c5-7bb7-4db4-9f15-390468c2f92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adamax(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "loss_train_list=[]\n",
    "acc_train_list=[]\n",
    "acc_val_list=[]\n",
    "epoch_save=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde9297-3136-440d-a8a1-eadd0aa5de06",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b446b769-7619-4dc6-85d5-3e3b0eb0fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0%]\tLoss: 0.690365\n",
      "Train Epoch: 0 [93%]\tLoss: 0.234365\n",
      "epoch 0 training loss: 0.4153240993963899 acc: 0.8158508158508159\n",
      "epoch 0 validation acc: 0.6111111\n",
      "Train Epoch: 1 [0%]\tLoss: 0.174468\n",
      "Train Epoch: 1 [93%]\tLoss: 0.626032\n",
      "epoch 1 training loss: 0.413716421669556 acc: 0.8041958041958042\n",
      "epoch 1 validation acc: 0.6203704\n",
      "Train Epoch: 2 [0%]\tLoss: 0.660497\n",
      "Train Epoch: 2 [93%]\tLoss: 0.369900\n",
      "epoch 2 training loss: 0.3882978275694229 acc: 0.8228438228438228\n",
      "epoch 2 validation acc: 0.6018519\n",
      "Train Epoch: 3 [0%]\tLoss: 0.304734\n",
      "Train Epoch: 3 [93%]\tLoss: 0.112679\n",
      "epoch 3 training loss: 0.39989553698924957 acc: 0.8181818181818182\n",
      "epoch 3 validation acc: 0.5092593\n",
      "Train Epoch: 4 [0%]\tLoss: 0.094074\n",
      "Train Epoch: 4 [93%]\tLoss: 0.200050\n",
      "epoch 4 training loss: 0.39446713582233145 acc: 0.8205128205128205\n",
      "epoch 4 validation acc: 0.7222222\n",
      "Train Epoch: 5 [0%]\tLoss: 0.563573\n",
      "Train Epoch: 5 [93%]\tLoss: 0.296456\n",
      "epoch 5 training loss: 0.41487687901179826 acc: 0.8181818181818182\n",
      "epoch 5 validation acc: 0.5925926\n",
      "Train Epoch: 6 [0%]\tLoss: 0.108910\n",
      "Train Epoch: 6 [93%]\tLoss: 0.355802\n",
      "epoch 6 training loss: 0.397967010353804 acc: 0.8018648018648019\n",
      "epoch 6 validation acc: 0.6944444\n",
      "Train Epoch: 7 [0%]\tLoss: 0.202734\n",
      "Train Epoch: 7 [93%]\tLoss: 1.130776\n",
      "epoch 7 training loss: 0.3920426028866873 acc: 0.8251748251748252\n",
      "epoch 7 validation acc: 0.5185185\n",
      "Train Epoch: 8 [0%]\tLoss: 0.401087\n",
      "Train Epoch: 8 [93%]\tLoss: 0.023744\n",
      "epoch 8 training loss: 0.3938403512195994 acc: 0.8088578088578089\n",
      "epoch 8 validation acc: 0.5462963\n",
      "Train Epoch: 9 [0%]\tLoss: 0.353049\n",
      "Train Epoch: 9 [93%]\tLoss: 0.111859\n",
      "epoch 9 training loss: 0.4177227703287456 acc: 0.8088578088578089\n",
      "epoch 9 validation acc: 0.7222222\n",
      "Train Epoch: 10 [0%]\tLoss: 0.132322\n",
      "Train Epoch: 10 [93%]\tLoss: 0.747047\n",
      "epoch 10 training loss: 0.3983934615109185 acc: 0.8228438228438228\n",
      "epoch 10 validation acc: 0.6759259\n",
      "Train Epoch: 11 [0%]\tLoss: 0.117536\n",
      "Train Epoch: 11 [93%]\tLoss: 0.437692\n",
      "epoch 11 training loss: 0.4119729469012883 acc: 0.8111888111888111\n",
      "epoch 11 validation acc: 0.6481481\n",
      "Train Epoch: 12 [0%]\tLoss: 0.459682\n",
      "Train Epoch: 12 [93%]\tLoss: 0.122220\n",
      "epoch 12 training loss: 0.40590430368212294 acc: 0.8041958041958042\n",
      "epoch 12 validation acc: 0.6759259\n",
      "Train Epoch: 13 [0%]\tLoss: 0.206732\n",
      "Train Epoch: 13 [93%]\tLoss: 0.295692\n",
      "epoch 13 training loss: 0.3781921470535626 acc: 0.8438228438228438\n",
      "epoch 13 validation acc: 0.6481481\n",
      "Train Epoch: 14 [0%]\tLoss: 0.188786\n",
      "Train Epoch: 14 [93%]\tLoss: 0.553096\n",
      "epoch 14 training loss: 0.38942295337889204 acc: 0.8275058275058275\n",
      "epoch 14 validation acc: 0.712963\n",
      "Train Epoch: 15 [0%]\tLoss: 0.124945\n",
      "Train Epoch: 15 [93%]\tLoss: 0.457171\n",
      "epoch 15 training loss: 0.38621624196875254 acc: 0.8181818181818182\n",
      "epoch 15 validation acc: 0.6944444\n",
      "Train Epoch: 16 [0%]\tLoss: 0.217884\n",
      "Train Epoch: 16 [93%]\tLoss: 0.066106\n",
      "epoch 16 training loss: 0.4205610177445191 acc: 0.8251748251748252\n",
      "epoch 16 validation acc: 0.5833333\n",
      "Train Epoch: 17 [0%]\tLoss: 0.147820\n",
      "Train Epoch: 17 [93%]\tLoss: 0.099745\n",
      "epoch 17 training loss: 0.4088395959870131 acc: 0.8251748251748252\n",
      "epoch 17 validation acc: 0.6388889\n",
      "Train Epoch: 18 [0%]\tLoss: 0.226984\n",
      "Train Epoch: 18 [93%]\tLoss: 0.177863\n",
      "epoch 18 training loss: 0.4016208440341331 acc: 0.8275058275058275\n",
      "epoch 18 validation acc: 0.6481481\n",
      "Train Epoch: 19 [0%]\tLoss: 0.529246\n",
      "Train Epoch: 19 [93%]\tLoss: 0.581752\n",
      "epoch 19 training loss: 0.4400662165135145 acc: 0.8251748251748252\n",
      "epoch 19 validation acc: 0.6481481\n",
      "Train Epoch: 20 [0%]\tLoss: 0.676248\n",
      "Train Epoch: 20 [93%]\tLoss: 0.086799\n",
      "epoch 20 training loss: 0.39962854731345065 acc: 0.8228438228438228\n",
      "epoch 20 validation acc: 0.6203704\n",
      "Train Epoch: 21 [0%]\tLoss: 0.279498\n",
      "Train Epoch: 21 [93%]\tLoss: 0.573856\n",
      "epoch 21 training loss: 0.42279999337538526 acc: 0.7995337995337995\n",
      "epoch 21 validation acc: 0.537037\n",
      "Train Epoch: 22 [0%]\tLoss: 0.128380\n",
      "Train Epoch: 22 [93%]\tLoss: 0.142015\n",
      "epoch 22 training loss: 0.3904222896520945 acc: 0.8181818181818182\n",
      "epoch 22 validation acc: 0.6944444\n",
      "Train Epoch: 23 [0%]\tLoss: 0.154565\n",
      "Train Epoch: 23 [93%]\tLoss: 0.553661\n",
      "epoch 23 training loss: 0.3786822245111344 acc: 0.8344988344988346\n",
      "epoch 23 validation acc: 0.6574074\n",
      "Train Epoch: 24 [0%]\tLoss: 0.384760\n",
      "Train Epoch: 24 [93%]\tLoss: 0.197786\n",
      "epoch 24 training loss: 0.4095456757824178 acc: 0.8088578088578089\n",
      "epoch 24 validation acc: 0.6111111\n",
      "Train Epoch: 25 [0%]\tLoss: 0.197873\n",
      "Train Epoch: 25 [93%]\tLoss: 0.388744\n",
      "epoch 25 training loss: 0.402466204120881 acc: 0.8275058275058275\n",
      "epoch 25 validation acc: 0.6018519\n",
      "Train Epoch: 26 [0%]\tLoss: 0.264418\n",
      "Train Epoch: 26 [93%]\tLoss: 0.342143\n",
      "epoch 26 training loss: 0.40918909830765593 acc: 0.8135198135198135\n",
      "epoch 26 validation acc: 0.5925926\n",
      "Train Epoch: 27 [0%]\tLoss: 0.369616\n",
      "Train Epoch: 27 [93%]\tLoss: 1.121792\n",
      "epoch 27 training loss: 0.3997835246156211 acc: 0.8088578088578089\n",
      "epoch 27 validation acc: 0.5462963\n",
      "Train Epoch: 28 [0%]\tLoss: 0.333711\n",
      "Train Epoch: 28 [93%]\tLoss: 0.386828\n",
      "epoch 28 training loss: 0.40641134006458474 acc: 0.8205128205128205\n",
      "epoch 28 validation acc: 0.6759259\n",
      "Train Epoch: 29 [0%]\tLoss: 0.239858\n",
      "Train Epoch: 29 [93%]\tLoss: 0.137436\n",
      "epoch 29 training loss: 0.387527130036216 acc: 0.8391608391608392\n",
      "epoch 29 validation acc: 0.6203704\n",
      "Train Epoch: 30 [0%]\tLoss: 0.107812\n",
      "Train Epoch: 30 [93%]\tLoss: 0.142122\n",
      "epoch 30 training loss: 0.4198701245089372 acc: 0.8228438228438228\n",
      "epoch 30 validation acc: 0.6203704\n",
      "Train Epoch: 31 [0%]\tLoss: 0.144060\n",
      "Train Epoch: 31 [93%]\tLoss: 0.089549\n",
      "epoch 31 training loss: 0.351207946634127 acc: 0.8671328671328671\n",
      "epoch 31 validation acc: 0.6203704\n",
      "Train Epoch: 32 [0%]\tLoss: 0.582713\n",
      "Train Epoch: 32 [93%]\tLoss: 0.215632\n",
      "epoch 32 training loss: 0.38659812577275765 acc: 0.8344988344988346\n",
      "epoch 32 validation acc: 0.537037\n",
      "Train Epoch: 33 [0%]\tLoss: 0.157928\n",
      "Train Epoch: 33 [93%]\tLoss: 0.555831\n",
      "epoch 33 training loss: 0.37713489095094027 acc: 0.8508158508158508\n",
      "epoch 33 validation acc: 0.6666667\n",
      "Train Epoch: 34 [0%]\tLoss: 0.319726\n",
      "Train Epoch: 34 [93%]\tLoss: 0.801439\n",
      "epoch 34 training loss: 0.39103644098914053 acc: 0.8391608391608392\n",
      "epoch 34 validation acc: 0.6111111\n",
      "Train Epoch: 35 [0%]\tLoss: 0.262806\n",
      "Train Epoch: 35 [93%]\tLoss: 0.230778\n",
      "epoch 35 training loss: 0.37593037800656426 acc: 0.8205128205128205\n",
      "epoch 35 validation acc: 0.6388889\n",
      "Train Epoch: 36 [0%]\tLoss: 0.396141\n",
      "Train Epoch: 36 [93%]\tLoss: 0.051377\n",
      "epoch 36 training loss: 0.3887095073651936 acc: 0.8298368298368298\n",
      "epoch 36 validation acc: 0.41666666\n",
      "Train Epoch: 37 [0%]\tLoss: 0.124869\n",
      "Train Epoch: 37 [93%]\tLoss: 0.260858\n",
      "epoch 37 training loss: 0.3811870119361966 acc: 0.8228438228438228\n",
      "epoch 37 validation acc: 0.5740741\n",
      "Train Epoch: 38 [0%]\tLoss: 0.100221\n",
      "Train Epoch: 38 [93%]\tLoss: 0.120750\n",
      "epoch 38 training loss: 0.37137637072656715 acc: 0.8391608391608392\n",
      "epoch 38 validation acc: 0.5462963\n",
      "Train Epoch: 39 [0%]\tLoss: 0.094444\n",
      "Train Epoch: 39 [93%]\tLoss: 0.174583\n",
      "epoch 39 training loss: 0.36133222709651347 acc: 0.8461538461538461\n",
      "epoch 39 validation acc: 0.5740741\n",
      "Train Epoch: 40 [0%]\tLoss: 0.505377\n",
      "Train Epoch: 40 [93%]\tLoss: 0.604139\n",
      "epoch 40 training loss: 0.37629557249170764 acc: 0.8391608391608392\n",
      "epoch 40 validation acc: 0.6944444\n",
      "Train Epoch: 41 [0%]\tLoss: 0.471542\n",
      "Train Epoch: 41 [93%]\tLoss: 0.510660\n",
      "epoch 41 training loss: 0.3900060266152852 acc: 0.8111888111888111\n",
      "epoch 41 validation acc: 0.6481481\n",
      "Train Epoch: 42 [0%]\tLoss: 0.734996\n",
      "Train Epoch: 42 [93%]\tLoss: 0.207662\n",
      "epoch 42 training loss: 0.4018332804725678 acc: 0.8111888111888111\n",
      "epoch 42 validation acc: 0.7037037\n",
      "Train Epoch: 43 [0%]\tLoss: 0.569096\n",
      "Train Epoch: 43 [93%]\tLoss: 0.244314\n",
      "epoch 43 training loss: 0.41609098864029403 acc: 0.8111888111888111\n",
      "epoch 43 validation acc: 0.6574074\n",
      "Train Epoch: 44 [0%]\tLoss: 0.574391\n",
      "Train Epoch: 44 [93%]\tLoss: 0.778613\n",
      "epoch 44 training loss: 0.37762714612849607 acc: 0.8275058275058275\n",
      "epoch 44 validation acc: 0.6018519\n",
      "Train Epoch: 45 [0%]\tLoss: 0.245601\n",
      "Train Epoch: 45 [93%]\tLoss: 0.341237\n",
      "epoch 45 training loss: 0.3880227788058282 acc: 0.8298368298368298\n",
      "epoch 45 validation acc: 0.6111111\n",
      "Train Epoch: 46 [0%]\tLoss: 0.662362\n",
      "Train Epoch: 46 [93%]\tLoss: 0.495740\n",
      "epoch 46 training loss: 0.37746984380538817 acc: 0.8251748251748252\n",
      "epoch 46 validation acc: 0.5925926\n",
      "Train Epoch: 47 [0%]\tLoss: 0.468160\n",
      "Train Epoch: 47 [93%]\tLoss: 0.908199\n",
      "epoch 47 training loss: 0.3600825595279242 acc: 0.8368298368298368\n",
      "epoch 47 validation acc: 0.6666667\n",
      "Train Epoch: 48 [0%]\tLoss: 0.184476\n",
      "Train Epoch: 48 [93%]\tLoss: 1.011770\n",
      "epoch 48 training loss: 0.3594853939074609 acc: 0.8438228438228438\n",
      "epoch 48 validation acc: 0.5\n",
      "Train Epoch: 49 [0%]\tLoss: 0.493349\n",
      "Train Epoch: 49 [93%]\tLoss: 0.398027\n",
      "epoch 49 training loss: 0.38643927246179105 acc: 0.8181818181818182\n",
      "epoch 49 validation acc: 0.712963\n",
      "Train Epoch: 50 [0%]\tLoss: 1.055674\n",
      "Train Epoch: 50 [93%]\tLoss: 0.685581\n",
      "epoch 50 training loss: 0.36782403438593503 acc: 0.8321678321678322\n",
      "epoch 50 validation acc: 0.5833333\n",
      "Train Epoch: 51 [0%]\tLoss: 0.537882\n",
      "Train Epoch: 51 [93%]\tLoss: 0.063661\n",
      "epoch 51 training loss: 0.3853964075722076 acc: 0.8205128205128205\n",
      "epoch 51 validation acc: 0.6203704\n",
      "Train Epoch: 52 [0%]\tLoss: 0.106285\n",
      "Train Epoch: 52 [93%]\tLoss: 0.579784\n",
      "epoch 52 training loss: 0.3494693567476201 acc: 0.8414918414918415\n",
      "epoch 52 validation acc: 0.6481481\n",
      "Train Epoch: 53 [0%]\tLoss: 0.473243\n",
      "Train Epoch: 53 [93%]\tLoss: 0.616975\n",
      "epoch 53 training loss: 0.40006959272755516 acc: 0.8275058275058275\n",
      "epoch 53 validation acc: 0.5185185\n",
      "Train Epoch: 54 [0%]\tLoss: 0.078215\n",
      "Train Epoch: 54 [93%]\tLoss: 0.431454\n",
      "epoch 54 training loss: 0.3694440850155876 acc: 0.8275058275058275\n",
      "epoch 54 validation acc: 0.6388889\n",
      "Train Epoch: 55 [0%]\tLoss: 0.469338\n",
      "Train Epoch: 55 [93%]\tLoss: 0.585252\n",
      "epoch 55 training loss: 0.38903253325433645 acc: 0.8251748251748252\n",
      "epoch 55 validation acc: 0.6574074\n",
      "Train Epoch: 56 [0%]\tLoss: 0.821151\n",
      "Train Epoch: 56 [93%]\tLoss: 0.061431\n",
      "epoch 56 training loss: 0.35469391641069065 acc: 0.8508158508158508\n",
      "epoch 56 validation acc: 0.537037\n",
      "Train Epoch: 57 [0%]\tLoss: 0.230888\n",
      "Train Epoch: 57 [93%]\tLoss: 0.253792\n",
      "epoch 57 training loss: 0.4001556984666321 acc: 0.8251748251748252\n",
      "epoch 57 validation acc: 0.5925926\n",
      "Train Epoch: 58 [0%]\tLoss: 0.363840\n",
      "Train Epoch: 58 [93%]\tLoss: 0.093501\n",
      "epoch 58 training loss: 0.39647058197469626 acc: 0.8438228438228438\n",
      "epoch 58 validation acc: 0.6851852\n",
      "Train Epoch: 59 [0%]\tLoss: 0.020392\n",
      "Train Epoch: 59 [93%]\tLoss: 0.873012\n",
      "epoch 59 training loss: 0.39762359441051054 acc: 0.8158508158508159\n",
      "epoch 59 validation acc: 0.7407407\n",
      "Train Epoch: 60 [0%]\tLoss: 0.134583\n",
      "Train Epoch: 60 [93%]\tLoss: 0.507284\n",
      "epoch 60 training loss: 0.3840300677758124 acc: 0.8298368298368298\n",
      "epoch 60 validation acc: 0.6018519\n",
      "Train Epoch: 61 [0%]\tLoss: 0.282718\n",
      "Train Epoch: 61 [93%]\tLoss: 0.479940\n",
      "epoch 61 training loss: 0.3557203695591953 acc: 0.8251748251748252\n",
      "epoch 61 validation acc: 0.6851852\n",
      "Train Epoch: 62 [0%]\tLoss: 0.201720\n",
      "Train Epoch: 62 [93%]\tLoss: 0.107768\n",
      "epoch 62 training loss: 0.3644480360844345 acc: 0.8344988344988346\n",
      "epoch 62 validation acc: 0.6296296\n",
      "Train Epoch: 63 [0%]\tLoss: 0.059204\n",
      "Train Epoch: 63 [93%]\tLoss: 0.490196\n",
      "epoch 63 training loss: 0.38385232546608206 acc: 0.8111888111888111\n",
      "epoch 63 validation acc: 0.5277778\n",
      "Train Epoch: 64 [0%]\tLoss: 0.771764\n",
      "Train Epoch: 64 [93%]\tLoss: 0.405529\n",
      "epoch 64 training loss: 0.3816548418318335 acc: 0.8135198135198135\n",
      "epoch 64 validation acc: 0.6759259\n",
      "Train Epoch: 65 [0%]\tLoss: 0.252372\n",
      "Train Epoch: 65 [93%]\tLoss: 0.107827\n",
      "epoch 65 training loss: 0.37955003177544483 acc: 0.8508158508158508\n",
      "epoch 65 validation acc: 0.6851852\n",
      "Train Epoch: 66 [0%]\tLoss: 0.114008\n",
      "Train Epoch: 66 [93%]\tLoss: 0.076138\n",
      "epoch 66 training loss: 0.38226437768726435 acc: 0.8321678321678322\n",
      "epoch 66 validation acc: 0.712963\n",
      "Train Epoch: 67 [0%]\tLoss: 0.089003\n",
      "Train Epoch: 67 [93%]\tLoss: 0.795549\n",
      "epoch 67 training loss: 0.37563536481724846 acc: 0.8275058275058275\n",
      "epoch 67 validation acc: 0.7222222\n",
      "Train Epoch: 68 [0%]\tLoss: 0.257799\n",
      "Train Epoch: 68 [93%]\tLoss: 0.327701\n",
      "epoch 68 training loss: 0.38659964146076903 acc: 0.8158508158508159\n",
      "epoch 68 validation acc: 0.7222222\n",
      "Train Epoch: 69 [0%]\tLoss: 0.265049\n",
      "Train Epoch: 69 [93%]\tLoss: 0.258342\n",
      "epoch 69 training loss: 0.35854252032866635 acc: 0.8461538461538461\n",
      "epoch 69 validation acc: 0.6018519\n",
      "Train Epoch: 70 [0%]\tLoss: 0.119847\n",
      "Train Epoch: 70 [93%]\tLoss: 1.074079\n",
      "epoch 70 training loss: 0.3808593629445467 acc: 0.8368298368298368\n",
      "epoch 70 validation acc: 0.6388889\n",
      "Train Epoch: 71 [0%]\tLoss: 0.074516\n",
      "Train Epoch: 71 [93%]\tLoss: 0.128334\n",
      "epoch 71 training loss: 0.35615620402084597 acc: 0.8321678321678322\n",
      "epoch 71 validation acc: 0.7962963\n",
      "Train Epoch: 72 [0%]\tLoss: 0.365499\n",
      "Train Epoch: 72 [93%]\tLoss: 0.096189\n",
      "epoch 72 training loss: 0.38962319162156844 acc: 0.8391608391608392\n",
      "epoch 72 validation acc: 0.6666667\n",
      "Train Epoch: 73 [0%]\tLoss: 0.533024\n",
      "Train Epoch: 73 [93%]\tLoss: 0.277166\n",
      "epoch 73 training loss: 0.40221759818356345 acc: 0.8275058275058275\n",
      "epoch 73 validation acc: 0.5648148\n",
      "Train Epoch: 74 [0%]\tLoss: 0.268692\n",
      "Train Epoch: 74 [93%]\tLoss: 0.799678\n",
      "epoch 74 training loss: 0.36734041650952015 acc: 0.8554778554778555\n",
      "epoch 74 validation acc: 0.6574074\n",
      "Train Epoch: 75 [0%]\tLoss: 0.069586\n",
      "Train Epoch: 75 [93%]\tLoss: 0.200722\n",
      "epoch 75 training loss: 0.3874060649562765 acc: 0.8344988344988346\n",
      "epoch 75 validation acc: 0.6944444\n",
      "Train Epoch: 76 [0%]\tLoss: 0.328373\n",
      "Train Epoch: 76 [93%]\tLoss: 0.432646\n",
      "epoch 76 training loss: 0.37914804534779656 acc: 0.8275058275058275\n",
      "epoch 76 validation acc: 0.6666667\n",
      "Train Epoch: 77 [0%]\tLoss: 0.111149\n",
      "Train Epoch: 77 [93%]\tLoss: 0.314743\n",
      "epoch 77 training loss: 0.34815688041487225 acc: 0.8484848484848485\n",
      "epoch 77 validation acc: 0.6944444\n",
      "Train Epoch: 78 [0%]\tLoss: 0.405080\n",
      "Train Epoch: 78 [93%]\tLoss: 0.451972\n",
      "epoch 78 training loss: 0.3838605867284868 acc: 0.8414918414918415\n",
      "epoch 78 validation acc: 0.5648148\n",
      "Train Epoch: 79 [0%]\tLoss: 0.156294\n",
      "Train Epoch: 79 [93%]\tLoss: 0.146095\n",
      "epoch 79 training loss: 0.3623345147266432 acc: 0.8414918414918415\n",
      "epoch 79 validation acc: 0.6759259\n",
      "Train Epoch: 80 [0%]\tLoss: 0.517556\n",
      "Train Epoch: 80 [93%]\tLoss: 0.333621\n",
      "epoch 80 training loss: 0.3925281653387679 acc: 0.8275058275058275\n",
      "epoch 80 validation acc: 0.6851852\n",
      "Train Epoch: 81 [0%]\tLoss: 0.698663\n",
      "Train Epoch: 81 [93%]\tLoss: 0.496995\n",
      "epoch 81 training loss: 0.36302559836595144 acc: 0.8391608391608392\n",
      "epoch 81 validation acc: 0.6666667\n",
      "Train Epoch: 82 [0%]\tLoss: 0.142201\n",
      "Train Epoch: 82 [93%]\tLoss: 0.179283\n",
      "epoch 82 training loss: 0.3723468412817628 acc: 0.8228438228438228\n",
      "epoch 82 validation acc: 0.5277778\n",
      "Train Epoch: 83 [0%]\tLoss: 0.149624\n",
      "Train Epoch: 83 [93%]\tLoss: 0.123261\n",
      "epoch 83 training loss: 0.4011702116889258 acc: 0.8135198135198135\n",
      "epoch 83 validation acc: 0.6944444\n",
      "Train Epoch: 84 [0%]\tLoss: 0.305410\n",
      "Train Epoch: 84 [93%]\tLoss: 0.527928\n",
      "epoch 84 training loss: 0.3709429583288039 acc: 0.8391608391608392\n",
      "epoch 84 validation acc: 0.5277778\n",
      "Train Epoch: 85 [0%]\tLoss: 0.202776\n",
      "Train Epoch: 85 [93%]\tLoss: 0.484726\n",
      "epoch 85 training loss: 0.36159657984454596 acc: 0.8438228438228438\n",
      "epoch 85 validation acc: 0.6388889\n",
      "Train Epoch: 86 [0%]\tLoss: 0.829567\n",
      "Train Epoch: 86 [93%]\tLoss: 0.146170\n",
      "epoch 86 training loss: 0.3919524245171083 acc: 0.8205128205128205\n",
      "epoch 86 validation acc: 0.712963\n",
      "Train Epoch: 87 [0%]\tLoss: 0.367763\n",
      "Train Epoch: 87 [93%]\tLoss: 0.305225\n",
      "epoch 87 training loss: 0.35095884761324636 acc: 0.8344988344988346\n",
      "epoch 87 validation acc: 0.6944444\n",
      "Train Epoch: 88 [0%]\tLoss: 0.913636\n",
      "Train Epoch: 88 [93%]\tLoss: 0.175427\n",
      "epoch 88 training loss: 0.3607401207641319 acc: 0.8135198135198135\n",
      "epoch 88 validation acc: 0.5833333\n",
      "Train Epoch: 89 [0%]\tLoss: 0.097540\n",
      "Train Epoch: 89 [93%]\tLoss: 0.998724\n",
      "epoch 89 training loss: 0.3906693408309905 acc: 0.8251748251748252\n",
      "epoch 89 validation acc: 0.6944444\n",
      "Train Epoch: 90 [0%]\tLoss: 0.377953\n",
      "Train Epoch: 90 [93%]\tLoss: 1.208934\n",
      "epoch 90 training loss: 0.3861622665184162 acc: 0.8368298368298368\n",
      "epoch 90 validation acc: 0.6666667\n",
      "Train Epoch: 91 [0%]\tLoss: 0.173515\n",
      "Train Epoch: 91 [93%]\tLoss: 0.560666\n",
      "epoch 91 training loss: 0.3781400455713824 acc: 0.8205128205128205\n",
      "epoch 91 validation acc: 0.5925926\n",
      "Train Epoch: 92 [0%]\tLoss: 0.558164\n",
      "Train Epoch: 92 [93%]\tLoss: 0.301357\n",
      "epoch 92 training loss: 0.36081019440596857 acc: 0.8251748251748252\n",
      "epoch 92 validation acc: 0.6203704\n",
      "Train Epoch: 93 [0%]\tLoss: 0.090459\n",
      "Train Epoch: 93 [93%]\tLoss: 0.093299\n",
      "epoch 93 training loss: 0.35127209111427266 acc: 0.8298368298368298\n",
      "epoch 93 validation acc: 0.5648148\n",
      "Train Epoch: 94 [0%]\tLoss: 0.481921\n",
      "Train Epoch: 94 [93%]\tLoss: 0.408427\n",
      "epoch 94 training loss: 0.3765857903630671 acc: 0.8088578088578089\n",
      "epoch 94 validation acc: 0.6666667\n",
      "Train Epoch: 95 [0%]\tLoss: 0.951102\n",
      "Train Epoch: 95 [93%]\tLoss: 0.990631\n",
      "epoch 95 training loss: 0.358170043590858 acc: 0.8321678321678322\n",
      "epoch 95 validation acc: 0.6481481\n",
      "Train Epoch: 96 [0%]\tLoss: 0.696116\n",
      "Train Epoch: 96 [93%]\tLoss: 0.360181\n",
      "epoch 96 training loss: 0.36320746422279626 acc: 0.8414918414918415\n",
      "epoch 96 validation acc: 0.5\n",
      "Train Epoch: 97 [0%]\tLoss: 0.434568\n",
      "Train Epoch: 97 [93%]\tLoss: 0.113580\n",
      "epoch 97 training loss: 0.365230533021666 acc: 0.8391608391608392\n",
      "epoch 97 validation acc: 0.6388889\n",
      "Train Epoch: 98 [0%]\tLoss: 0.136837\n",
      "Train Epoch: 98 [93%]\tLoss: 0.155856\n",
      "epoch 98 training loss: 0.37037977646212783 acc: 0.8275058275058275\n",
      "epoch 98 validation acc: 0.7037037\n",
      "Train Epoch: 99 [0%]\tLoss: 0.081356\n",
      "Train Epoch: 99 [93%]\tLoss: 0.493817\n",
      "epoch 99 training loss: 0.35929228282637066 acc: 0.8461538461538461\n",
      "epoch 99 validation acc: 0.6203704\n",
      "Train Epoch: 100 [0%]\tLoss: 0.412259\n",
      "Train Epoch: 100 [93%]\tLoss: 0.373009\n",
      "epoch 100 training loss: 0.35280024599180454 acc: 0.8321678321678322\n",
      "epoch 100 validation acc: 0.6296296\n",
      "Train Epoch: 101 [0%]\tLoss: 0.162795\n",
      "Train Epoch: 101 [93%]\tLoss: 0.245035\n",
      "epoch 101 training loss: 0.3609398512290446 acc: 0.8275058275058275\n",
      "epoch 101 validation acc: 0.5833333\n",
      "Train Epoch: 102 [0%]\tLoss: 0.334867\n",
      "Train Epoch: 102 [93%]\tLoss: 0.423475\n",
      "epoch 102 training loss: 0.36843282122734106 acc: 0.8368298368298368\n",
      "epoch 102 validation acc: 0.712963\n",
      "Train Epoch: 103 [0%]\tLoss: 0.025485\n",
      "Train Epoch: 103 [93%]\tLoss: 0.253845\n",
      "epoch 103 training loss: 0.40522958810820625 acc: 0.8181818181818182\n",
      "epoch 103 validation acc: 0.6666667\n",
      "Train Epoch: 104 [0%]\tLoss: 0.379202\n",
      "Train Epoch: 104 [93%]\tLoss: 0.193257\n",
      "epoch 104 training loss: 0.3775028795245345 acc: 0.8181818181818182\n",
      "epoch 104 validation acc: 0.6296296\n",
      "Train Epoch: 105 [0%]\tLoss: 0.042764\n",
      "Train Epoch: 105 [93%]\tLoss: 0.564503\n",
      "epoch 105 training loss: 0.3702980621234962 acc: 0.8321678321678322\n",
      "epoch 105 validation acc: 0.6759259\n",
      "Train Epoch: 106 [0%]\tLoss: 0.389395\n",
      "Train Epoch: 106 [93%]\tLoss: 0.238785\n",
      "epoch 106 training loss: 0.3783913180921917 acc: 0.8298368298368298\n",
      "epoch 106 validation acc: 0.6018519\n",
      "Train Epoch: 107 [0%]\tLoss: 0.374324\n",
      "Train Epoch: 107 [93%]\tLoss: 0.144245\n",
      "epoch 107 training loss: 0.3556353075298291 acc: 0.8484848484848485\n",
      "epoch 107 validation acc: 0.537037\n",
      "Train Epoch: 108 [0%]\tLoss: 0.172066\n",
      "Train Epoch: 108 [93%]\tLoss: 0.566213\n",
      "epoch 108 training loss: 0.36569607516543734 acc: 0.8368298368298368\n",
      "epoch 108 validation acc: 0.5648148\n",
      "Train Epoch: 109 [0%]\tLoss: 0.304277\n",
      "Train Epoch: 109 [93%]\tLoss: 0.165544\n",
      "epoch 109 training loss: 0.3982680079147772 acc: 0.8251748251748252\n",
      "epoch 109 validation acc: 0.5833333\n",
      "Train Epoch: 110 [0%]\tLoss: 0.725320\n",
      "Train Epoch: 110 [93%]\tLoss: 0.247341\n",
      "epoch 110 training loss: 0.353014037776221 acc: 0.8461538461538461\n",
      "epoch 110 validation acc: 0.5462963\n",
      "Train Epoch: 111 [0%]\tLoss: 0.479632\n",
      "Train Epoch: 111 [93%]\tLoss: 0.766810\n",
      "epoch 111 training loss: 0.35647120102550145 acc: 0.8554778554778555\n",
      "epoch 111 validation acc: 0.6111111\n",
      "Train Epoch: 112 [0%]\tLoss: 0.366186\n",
      "Train Epoch: 112 [93%]\tLoss: 0.274553\n",
      "epoch 112 training loss: 0.3797392264349145 acc: 0.8321678321678322\n",
      "epoch 112 validation acc: 0.6481481\n",
      "Train Epoch: 113 [0%]\tLoss: 0.332421\n",
      "Train Epoch: 113 [93%]\tLoss: 0.299588\n",
      "epoch 113 training loss: 0.3671358239756349 acc: 0.8438228438228438\n",
      "epoch 113 validation acc: 0.5925926\n",
      "Train Epoch: 114 [0%]\tLoss: 0.419450\n",
      "Train Epoch: 114 [93%]\tLoss: 0.306476\n",
      "epoch 114 training loss: 0.3686338975266726 acc: 0.8368298368298368\n",
      "epoch 114 validation acc: 0.5740741\n",
      "Train Epoch: 115 [0%]\tLoss: 0.527213\n",
      "Train Epoch: 115 [93%]\tLoss: 0.521128\n",
      "epoch 115 training loss: 0.36557044359182733 acc: 0.8181818181818182\n",
      "epoch 115 validation acc: 0.5462963\n",
      "Train Epoch: 116 [0%]\tLoss: 0.092635\n",
      "Train Epoch: 116 [93%]\tLoss: 0.347964\n",
      "epoch 116 training loss: 0.3414460352828933 acc: 0.8461538461538461\n",
      "epoch 116 validation acc: 0.6759259\n",
      "Train Epoch: 117 [0%]\tLoss: 0.107433\n",
      "Train Epoch: 117 [93%]\tLoss: 0.284186\n",
      "epoch 117 training loss: 0.3441580501385033 acc: 0.8321678321678322\n",
      "epoch 117 validation acc: 0.46296296\n",
      "Train Epoch: 118 [0%]\tLoss: 0.189736\n",
      "Train Epoch: 118 [93%]\tLoss: 0.317959\n",
      "epoch 118 training loss: 0.3313982661865238 acc: 0.8344988344988346\n",
      "epoch 118 validation acc: 0.5833333\n",
      "Train Epoch: 119 [0%]\tLoss: 0.312033\n",
      "Train Epoch: 119 [93%]\tLoss: 0.732816\n",
      "epoch 119 training loss: 0.3535690053012567 acc: 0.8438228438228438\n",
      "epoch 119 validation acc: 0.6296296\n",
      "Train Epoch: 120 [0%]\tLoss: 0.746046\n",
      "Train Epoch: 120 [93%]\tLoss: 0.418242\n",
      "epoch 120 training loss: 0.343945316116636 acc: 0.8508158508158508\n",
      "epoch 120 validation acc: 0.6018519\n",
      "Train Epoch: 121 [0%]\tLoss: 0.645550\n",
      "Train Epoch: 121 [93%]\tLoss: 0.100633\n",
      "epoch 121 training loss: 0.34326873122093576 acc: 0.8414918414918415\n",
      "epoch 121 validation acc: 0.5277778\n",
      "Train Epoch: 122 [0%]\tLoss: 0.100180\n",
      "Train Epoch: 122 [93%]\tLoss: 0.594598\n",
      "epoch 122 training loss: 0.39944989954259386 acc: 0.8321678321678322\n",
      "epoch 122 validation acc: 0.5925926\n",
      "Train Epoch: 123 [0%]\tLoss: 0.189515\n",
      "Train Epoch: 123 [93%]\tLoss: 0.340496\n",
      "epoch 123 training loss: 0.36563612713857935 acc: 0.8344988344988346\n",
      "epoch 123 validation acc: 0.5648148\n",
      "Train Epoch: 124 [0%]\tLoss: 0.738645\n",
      "Train Epoch: 124 [93%]\tLoss: 0.091799\n",
      "epoch 124 training loss: 0.36212938594097205 acc: 0.8298368298368298\n",
      "epoch 124 validation acc: 0.6111111\n",
      "Train Epoch: 125 [0%]\tLoss: 0.174186\n",
      "Train Epoch: 125 [93%]\tLoss: 0.450841\n",
      "epoch 125 training loss: 0.357720242364815 acc: 0.8414918414918415\n",
      "epoch 125 validation acc: 0.5833333\n",
      "Train Epoch: 126 [0%]\tLoss: 0.181366\n",
      "Train Epoch: 126 [93%]\tLoss: 0.046289\n",
      "epoch 126 training loss: 0.3415708204610618 acc: 0.8554778554778555\n",
      "epoch 126 validation acc: 0.5925926\n",
      "Train Epoch: 127 [0%]\tLoss: 0.500611\n",
      "Train Epoch: 127 [93%]\tLoss: 1.003091\n",
      "epoch 127 training loss: 0.3731956526085182 acc: 0.8228438228438228\n",
      "epoch 127 validation acc: 0.6018519\n",
      "Train Epoch: 128 [0%]\tLoss: 0.070385\n",
      "Train Epoch: 128 [93%]\tLoss: 0.318014\n",
      "epoch 128 training loss: 0.3528904195409268 acc: 0.8601398601398601\n",
      "epoch 128 validation acc: 0.537037\n",
      "Train Epoch: 129 [0%]\tLoss: 0.106904\n",
      "Train Epoch: 129 [93%]\tLoss: 0.227063\n",
      "epoch 129 training loss: 0.34234801236609064 acc: 0.8484848484848485\n",
      "epoch 129 validation acc: 0.5648148\n",
      "Train Epoch: 130 [0%]\tLoss: 0.158084\n",
      "Train Epoch: 130 [93%]\tLoss: 0.188858\n",
      "epoch 130 training loss: 0.37380128838466825 acc: 0.8228438228438228\n",
      "epoch 130 validation acc: 0.6203704\n",
      "Train Epoch: 131 [0%]\tLoss: 0.138384\n",
      "Train Epoch: 131 [93%]\tLoss: 0.225665\n",
      "epoch 131 training loss: 0.38465258737819064 acc: 0.8275058275058275\n",
      "epoch 131 validation acc: 0.6111111\n",
      "Train Epoch: 132 [0%]\tLoss: 0.221916\n",
      "Train Epoch: 132 [93%]\tLoss: 0.055010\n",
      "epoch 132 training loss: 0.3392114227775622 acc: 0.8531468531468531\n",
      "epoch 132 validation acc: 0.6388889\n",
      "Train Epoch: 133 [0%]\tLoss: 0.212102\n",
      "Train Epoch: 133 [93%]\tLoss: 0.787837\n",
      "epoch 133 training loss: 0.3448353598020428 acc: 0.8368298368298368\n",
      "epoch 133 validation acc: 0.5833333\n",
      "Train Epoch: 134 [0%]\tLoss: 1.047089\n",
      "Train Epoch: 134 [93%]\tLoss: 0.508509\n",
      "epoch 134 training loss: 0.369712852995252 acc: 0.8368298368298368\n",
      "epoch 134 validation acc: 0.6851852\n",
      "Train Epoch: 135 [0%]\tLoss: 0.160566\n",
      "Train Epoch: 135 [93%]\tLoss: 0.182238\n",
      "epoch 135 training loss: 0.36288179026019796 acc: 0.8321678321678322\n",
      "epoch 135 validation acc: 0.6574074\n",
      "Train Epoch: 136 [0%]\tLoss: 0.568816\n",
      "Train Epoch: 136 [93%]\tLoss: 0.250222\n",
      "epoch 136 training loss: 0.34913250248603245 acc: 0.8414918414918415\n",
      "epoch 136 validation acc: 0.5925926\n",
      "Train Epoch: 137 [0%]\tLoss: 0.743782\n",
      "Train Epoch: 137 [93%]\tLoss: 0.340359\n",
      "epoch 137 training loss: 0.3577538699178991 acc: 0.8461538461538461\n",
      "epoch 137 validation acc: 0.5555556\n",
      "Train Epoch: 138 [0%]\tLoss: 0.289587\n",
      "Train Epoch: 138 [93%]\tLoss: 0.137641\n",
      "epoch 138 training loss: 0.37020496206565034 acc: 0.8251748251748252\n",
      "epoch 138 validation acc: 0.5555556\n",
      "Train Epoch: 139 [0%]\tLoss: 0.526827\n",
      "Train Epoch: 139 [93%]\tLoss: 0.522770\n",
      "epoch 139 training loss: 0.357710101072573 acc: 0.8554778554778555\n",
      "epoch 139 validation acc: 0.6666667\n",
      "Train Epoch: 140 [0%]\tLoss: 0.354938\n",
      "Train Epoch: 140 [93%]\tLoss: 0.349572\n",
      "epoch 140 training loss: 0.356204800042633 acc: 0.8391608391608392\n",
      "epoch 140 validation acc: 0.7037037\n",
      "Train Epoch: 141 [0%]\tLoss: 0.684392\n",
      "Train Epoch: 141 [93%]\tLoss: 0.071601\n",
      "epoch 141 training loss: 0.3788893262519398 acc: 0.8414918414918415\n",
      "epoch 141 validation acc: 0.5\n",
      "Train Epoch: 142 [0%]\tLoss: 0.089046\n",
      "Train Epoch: 142 [93%]\tLoss: 0.314669\n",
      "epoch 142 training loss: 0.3603927624493803 acc: 0.8321678321678322\n",
      "epoch 142 validation acc: 0.5555556\n",
      "Train Epoch: 143 [0%]\tLoss: 0.102727\n",
      "Train Epoch: 143 [93%]\tLoss: 0.107378\n",
      "epoch 143 training loss: 0.37766167451950927 acc: 0.8228438228438228\n",
      "epoch 143 validation acc: 0.4814815\n",
      "Train Epoch: 144 [0%]\tLoss: 0.067368\n",
      "Train Epoch: 144 [93%]\tLoss: 0.302427\n",
      "epoch 144 training loss: 0.36672490576489103 acc: 0.8438228438228438\n",
      "epoch 144 validation acc: 0.6666667\n",
      "Train Epoch: 145 [0%]\tLoss: 0.831312\n",
      "Train Epoch: 145 [93%]\tLoss: 0.138042\n",
      "epoch 145 training loss: 0.3385045385264136 acc: 0.8578088578088578\n",
      "epoch 145 validation acc: 0.6203704\n",
      "Train Epoch: 146 [0%]\tLoss: 0.312360\n",
      "Train Epoch: 146 [93%]\tLoss: 0.628651\n",
      "epoch 146 training loss: 0.33119342549428066 acc: 0.8391608391608392\n",
      "epoch 146 validation acc: 0.6203704\n",
      "Train Epoch: 147 [0%]\tLoss: 0.227883\n",
      "Train Epoch: 147 [93%]\tLoss: 0.112568\n",
      "epoch 147 training loss: 0.3516554056674337 acc: 0.8414918414918415\n",
      "epoch 147 validation acc: 0.6574074\n",
      "Train Epoch: 148 [0%]\tLoss: 0.085199\n",
      "Train Epoch: 148 [93%]\tLoss: 0.223832\n",
      "epoch 148 training loss: 0.3674984893727082 acc: 0.8298368298368298\n",
      "epoch 148 validation acc: 0.6944444\n",
      "Train Epoch: 149 [0%]\tLoss: 0.146360\n",
      "Train Epoch: 149 [93%]\tLoss: 0.082051\n",
      "epoch 149 training loss: 0.3092804553539113 acc: 0.8671328671328671\n",
      "epoch 149 validation acc: 0.6388889\n",
      "Train Epoch: 150 [0%]\tLoss: 0.245366\n",
      "Train Epoch: 150 [93%]\tLoss: 0.408195\n",
      "epoch 150 training loss: 0.3428489144027009 acc: 0.8461538461538461\n",
      "epoch 150 validation acc: 0.6759259\n",
      "Train Epoch: 151 [0%]\tLoss: 0.775123\n",
      "Train Epoch: 151 [93%]\tLoss: 0.081141\n",
      "epoch 151 training loss: 0.35229165731342854 acc: 0.8438228438228438\n",
      "epoch 151 validation acc: 0.6574074\n",
      "Train Epoch: 152 [0%]\tLoss: 0.041005\n",
      "Train Epoch: 152 [93%]\tLoss: 0.030020\n",
      "epoch 152 training loss: 0.3315360164388376 acc: 0.8578088578088578\n",
      "epoch 152 validation acc: 0.6666667\n",
      "Train Epoch: 153 [0%]\tLoss: 0.078685\n",
      "Train Epoch: 153 [93%]\tLoss: 0.095750\n",
      "epoch 153 training loss: 0.344550049363601 acc: 0.8508158508158508\n",
      "epoch 153 validation acc: 0.5092593\n",
      "Train Epoch: 154 [0%]\tLoss: 0.430149\n",
      "Train Epoch: 154 [93%]\tLoss: 0.109772\n",
      "epoch 154 training loss: 0.3610325443679122 acc: 0.8344988344988346\n",
      "epoch 154 validation acc: 0.6759259\n",
      "Train Epoch: 155 [0%]\tLoss: 0.426347\n",
      "Train Epoch: 155 [93%]\tLoss: 0.332052\n",
      "epoch 155 training loss: 0.33385671455633 acc: 0.8694638694638694\n",
      "epoch 155 validation acc: 0.5833333\n",
      "Train Epoch: 156 [0%]\tLoss: 0.211618\n",
      "Train Epoch: 156 [93%]\tLoss: 1.090225\n",
      "epoch 156 training loss: 0.3364417626742377 acc: 0.8461538461538461\n",
      "epoch 156 validation acc: 0.6666667\n",
      "Train Epoch: 157 [0%]\tLoss: 0.496178\n",
      "Train Epoch: 157 [93%]\tLoss: 0.089643\n",
      "epoch 157 training loss: 0.3419619852820351 acc: 0.8531468531468531\n",
      "epoch 157 validation acc: 0.5648148\n",
      "Train Epoch: 158 [0%]\tLoss: 0.305486\n",
      "Train Epoch: 158 [93%]\tLoss: 0.961842\n",
      "epoch 158 training loss: 0.3281380647741672 acc: 0.8578088578088578\n",
      "epoch 158 validation acc: 0.5555556\n",
      "Train Epoch: 159 [0%]\tLoss: 0.578167\n",
      "Train Epoch: 159 [93%]\tLoss: 0.615807\n",
      "epoch 159 training loss: 0.3630130833049339 acc: 0.8275058275058275\n",
      "epoch 159 validation acc: 0.5925926\n",
      "Train Epoch: 160 [0%]\tLoss: 0.194741\n",
      "Train Epoch: 160 [93%]\tLoss: 0.235365\n",
      "epoch 160 training loss: 0.37697521652336474 acc: 0.8391608391608392\n",
      "epoch 160 validation acc: 0.5648148\n",
      "Train Epoch: 161 [0%]\tLoss: 0.161292\n",
      "Train Epoch: 161 [93%]\tLoss: 0.323401\n",
      "epoch 161 training loss: 0.327657287899422 acc: 0.8624708624708625\n",
      "epoch 161 validation acc: 0.5925926\n",
      "Train Epoch: 162 [0%]\tLoss: 0.128856\n",
      "Train Epoch: 162 [93%]\tLoss: 0.092964\n",
      "epoch 162 training loss: 0.33695148390338375 acc: 0.8531468531468531\n",
      "epoch 162 validation acc: 0.5277778\n",
      "Train Epoch: 163 [0%]\tLoss: 0.034491\n",
      "Train Epoch: 163 [93%]\tLoss: 0.160423\n",
      "epoch 163 training loss: 0.41336329336519595 acc: 0.8275058275058275\n",
      "epoch 163 validation acc: 0.5277778\n",
      "Train Epoch: 164 [0%]\tLoss: 0.233084\n",
      "Train Epoch: 164 [93%]\tLoss: 0.160334\n",
      "epoch 164 training loss: 0.33636311032912797 acc: 0.8414918414918415\n",
      "epoch 164 validation acc: 0.6666667\n",
      "Train Epoch: 165 [0%]\tLoss: 0.443221\n",
      "Train Epoch: 165 [93%]\tLoss: 0.310743\n",
      "epoch 165 training loss: 0.3479028555167908 acc: 0.8321678321678322\n",
      "epoch 165 validation acc: 0.6481481\n",
      "Train Epoch: 166 [0%]\tLoss: 0.360880\n",
      "Train Epoch: 166 [93%]\tLoss: 0.471317\n",
      "epoch 166 training loss: 0.3333031338967245 acc: 0.8554778554778555\n",
      "epoch 166 validation acc: 0.5555556\n",
      "Train Epoch: 167 [0%]\tLoss: 0.046573\n",
      "Train Epoch: 167 [93%]\tLoss: 0.832596\n",
      "epoch 167 training loss: 0.328379322268086 acc: 0.8624708624708625\n",
      "epoch 167 validation acc: 0.537037\n",
      "Train Epoch: 168 [0%]\tLoss: 0.302470\n",
      "Train Epoch: 168 [93%]\tLoss: 0.623174\n",
      "epoch 168 training loss: 0.34377319169073384 acc: 0.8391608391608392\n",
      "epoch 168 validation acc: 0.6111111\n",
      "Train Epoch: 169 [0%]\tLoss: 0.246950\n",
      "Train Epoch: 169 [93%]\tLoss: 0.285558\n",
      "epoch 169 training loss: 0.37052293011435755 acc: 0.8275058275058275\n",
      "epoch 169 validation acc: 0.49074075\n",
      "Train Epoch: 170 [0%]\tLoss: 0.335500\n",
      "Train Epoch: 170 [93%]\tLoss: 0.076570\n",
      "epoch 170 training loss: 0.35293776152172573 acc: 0.8368298368298368\n",
      "epoch 170 validation acc: 0.6018519\n",
      "Train Epoch: 171 [0%]\tLoss: 0.562056\n",
      "Train Epoch: 171 [93%]\tLoss: 0.507310\n",
      "epoch 171 training loss: 0.33635556601695027 acc: 0.8717948717948718\n",
      "epoch 171 validation acc: 0.6388889\n",
      "Train Epoch: 172 [0%]\tLoss: 0.377030\n",
      "Train Epoch: 172 [93%]\tLoss: 0.627371\n",
      "epoch 172 training loss: 0.3427655426440416 acc: 0.8414918414918415\n",
      "epoch 172 validation acc: 0.6018519\n",
      "Train Epoch: 173 [0%]\tLoss: 0.460823\n",
      "Train Epoch: 173 [93%]\tLoss: 0.402240\n",
      "epoch 173 training loss: 0.3334349756111839 acc: 0.8461538461538461\n",
      "epoch 173 validation acc: 0.5925926\n",
      "Train Epoch: 174 [0%]\tLoss: 0.326438\n",
      "Train Epoch: 174 [93%]\tLoss: 0.540600\n",
      "epoch 174 training loss: 0.3918926138430834 acc: 0.8368298368298368\n",
      "epoch 174 validation acc: 0.6018519\n",
      "Train Epoch: 175 [0%]\tLoss: 1.214471\n",
      "Train Epoch: 175 [93%]\tLoss: 0.591213\n",
      "epoch 175 training loss: 0.3550504873920646 acc: 0.8344988344988346\n",
      "epoch 175 validation acc: 0.6759259\n",
      "Train Epoch: 176 [0%]\tLoss: 0.223742\n",
      "Train Epoch: 176 [93%]\tLoss: 0.468123\n",
      "epoch 176 training loss: 0.3698620929951883 acc: 0.8438228438228438\n",
      "epoch 176 validation acc: 0.5648148\n",
      "Train Epoch: 177 [0%]\tLoss: 0.178342\n",
      "Train Epoch: 177 [93%]\tLoss: 0.183010\n",
      "epoch 177 training loss: 0.3279889526311308 acc: 0.8578088578088578\n",
      "epoch 177 validation acc: 0.5462963\n",
      "Train Epoch: 178 [0%]\tLoss: 0.703542\n",
      "Train Epoch: 178 [93%]\tLoss: 0.065598\n",
      "epoch 178 training loss: 0.3355201960770905 acc: 0.8554778554778555\n",
      "epoch 178 validation acc: 0.5740741\n",
      "Train Epoch: 179 [0%]\tLoss: 0.420164\n",
      "Train Epoch: 179 [93%]\tLoss: 0.553760\n",
      "epoch 179 training loss: 0.39565830231057825 acc: 0.8484848484848485\n",
      "epoch 179 validation acc: 0.5555556\n",
      "Train Epoch: 180 [0%]\tLoss: 0.321062\n",
      "Train Epoch: 180 [93%]\tLoss: 0.070052\n",
      "epoch 180 training loss: 0.3175167280283791 acc: 0.8601398601398601\n",
      "epoch 180 validation acc: 0.6111111\n",
      "Train Epoch: 181 [0%]\tLoss: 0.088263\n",
      "Train Epoch: 181 [93%]\tLoss: 0.030589\n",
      "epoch 181 training loss: 0.3468490174833547 acc: 0.8601398601398601\n",
      "epoch 181 validation acc: 0.6574074\n",
      "Train Epoch: 182 [0%]\tLoss: 0.062975\n",
      "Train Epoch: 182 [93%]\tLoss: 1.270795\n",
      "epoch 182 training loss: 0.35515654649309536 acc: 0.8624708624708625\n",
      "epoch 182 validation acc: 0.6388889\n",
      "Train Epoch: 183 [0%]\tLoss: 0.026605\n",
      "Train Epoch: 183 [93%]\tLoss: 0.328134\n",
      "epoch 183 training loss: 0.31930564075931517 acc: 0.8508158508158508\n",
      "epoch 183 validation acc: 0.6666667\n",
      "Train Epoch: 184 [0%]\tLoss: 0.138512\n",
      "Train Epoch: 184 [93%]\tLoss: 1.007400\n",
      "epoch 184 training loss: 0.3388323562944101 acc: 0.8508158508158508\n",
      "epoch 184 validation acc: 0.6759259\n",
      "Train Epoch: 185 [0%]\tLoss: 0.084716\n",
      "Train Epoch: 185 [93%]\tLoss: 0.126747\n",
      "epoch 185 training loss: 0.35371241797865544 acc: 0.8275058275058275\n",
      "epoch 185 validation acc: 0.5833333\n",
      "Train Epoch: 186 [0%]\tLoss: 0.181670\n",
      "Train Epoch: 186 [93%]\tLoss: 0.426331\n",
      "epoch 186 training loss: 0.3581883185284419 acc: 0.8391608391608392\n",
      "epoch 186 validation acc: 0.46296296\n",
      "Train Epoch: 187 [0%]\tLoss: 0.136846\n",
      "Train Epoch: 187 [93%]\tLoss: 0.274432\n",
      "epoch 187 training loss: 0.34025260321451006 acc: 0.8391608391608392\n",
      "epoch 187 validation acc: 0.7314815\n",
      "Train Epoch: 188 [0%]\tLoss: 0.668334\n",
      "Train Epoch: 188 [93%]\tLoss: 0.263110\n",
      "epoch 188 training loss: 0.3660767609275084 acc: 0.8578088578088578\n",
      "epoch 188 validation acc: 0.5740741\n",
      "Train Epoch: 189 [0%]\tLoss: 0.517216\n",
      "Train Epoch: 189 [93%]\tLoss: 0.349982\n",
      "epoch 189 training loss: 0.3624145667913749 acc: 0.8368298368298368\n",
      "epoch 189 validation acc: 0.6203704\n",
      "Train Epoch: 190 [0%]\tLoss: 0.144943\n",
      "Train Epoch: 190 [93%]\tLoss: 0.512988\n",
      "epoch 190 training loss: 0.339406973882837 acc: 0.8601398601398601\n",
      "epoch 190 validation acc: 0.7222222\n",
      "Train Epoch: 191 [0%]\tLoss: 0.131873\n",
      "Train Epoch: 191 [93%]\tLoss: 0.289060\n",
      "epoch 191 training loss: 0.3418565955599425 acc: 0.8414918414918415\n",
      "epoch 191 validation acc: 0.5648148\n",
      "Train Epoch: 192 [0%]\tLoss: 0.189654\n",
      "Train Epoch: 192 [93%]\tLoss: 0.434439\n",
      "epoch 192 training loss: 0.31975545885938184 acc: 0.8648018648018648\n",
      "epoch 192 validation acc: 0.6296296\n",
      "Train Epoch: 193 [0%]\tLoss: 0.342898\n",
      "Train Epoch: 193 [93%]\tLoss: 0.291294\n",
      "epoch 193 training loss: 0.3572357629506129 acc: 0.8484848484848485\n",
      "epoch 193 validation acc: 0.5648148\n",
      "Train Epoch: 194 [0%]\tLoss: 0.061854\n",
      "Train Epoch: 194 [93%]\tLoss: 0.227530\n",
      "epoch 194 training loss: 0.3197729526038057 acc: 0.8531468531468531\n",
      "epoch 194 validation acc: 0.7037037\n",
      "Train Epoch: 195 [0%]\tLoss: 0.697837\n",
      "Train Epoch: 195 [93%]\tLoss: 0.537183\n",
      "epoch 195 training loss: 0.33818013368916044 acc: 0.8368298368298368\n",
      "epoch 195 validation acc: 0.6851852\n",
      "Train Epoch: 196 [0%]\tLoss: 0.048024\n",
      "Train Epoch: 196 [93%]\tLoss: 0.309712\n",
      "epoch 196 training loss: 0.37579332846885166 acc: 0.8508158508158508\n",
      "epoch 196 validation acc: 0.5462963\n",
      "Train Epoch: 197 [0%]\tLoss: 0.263886\n",
      "Train Epoch: 197 [93%]\tLoss: 0.124364\n",
      "epoch 197 training loss: 0.34180405113363155 acc: 0.8438228438228438\n",
      "epoch 197 validation acc: 0.537037\n",
      "Train Epoch: 198 [0%]\tLoss: 0.330389\n",
      "Train Epoch: 198 [93%]\tLoss: 0.295105\n",
      "epoch 198 training loss: 0.3409431744366884 acc: 0.8391608391608392\n",
      "epoch 198 validation acc: 0.5833333\n",
      "Train Epoch: 199 [0%]\tLoss: 0.355727\n",
      "Train Epoch: 199 [93%]\tLoss: 0.169295\n",
      "epoch 199 training loss: 0.3511388268972816 acc: 0.8251748251748252\n",
      "epoch 199 validation acc: 0.5648148\n",
      "Train Epoch: 200 [0%]\tLoss: 0.722111\n",
      "Train Epoch: 200 [93%]\tLoss: 0.463144\n",
      "epoch 200 training loss: 0.3559708362962637 acc: 0.8484848484848485\n",
      "epoch 200 validation acc: 0.6203704\n",
      "Train Epoch: 201 [0%]\tLoss: 0.115108\n",
      "Train Epoch: 201 [93%]\tLoss: 0.297655\n",
      "epoch 201 training loss: 0.3355456702756109 acc: 0.8648018648018648\n",
      "epoch 201 validation acc: 0.6203704\n",
      "Train Epoch: 202 [0%]\tLoss: 0.168736\n",
      "Train Epoch: 202 [93%]\tLoss: 0.087421\n",
      "epoch 202 training loss: 0.3215956928518911 acc: 0.8694638694638694\n",
      "epoch 202 validation acc: 0.537037\n",
      "Train Epoch: 203 [0%]\tLoss: 0.319967\n",
      "Train Epoch: 203 [93%]\tLoss: 0.074280\n",
      "epoch 203 training loss: 0.32236558236871604 acc: 0.8578088578088578\n",
      "epoch 203 validation acc: 0.5555556\n",
      "Train Epoch: 204 [0%]\tLoss: 0.235288\n",
      "Train Epoch: 204 [93%]\tLoss: 0.521621\n",
      "epoch 204 training loss: 0.34722606749144486 acc: 0.8391608391608392\n",
      "epoch 204 validation acc: 0.6296296\n",
      "Train Epoch: 205 [0%]\tLoss: 0.125729\n",
      "Train Epoch: 205 [93%]\tLoss: 0.238841\n",
      "epoch 205 training loss: 0.31944155296379767 acc: 0.8578088578088578\n",
      "epoch 205 validation acc: 0.5185185\n",
      "Train Epoch: 206 [0%]\tLoss: 0.090918\n",
      "Train Epoch: 206 [93%]\tLoss: 0.211019\n",
      "epoch 206 training loss: 0.31311211614283146 acc: 0.8811188811188811\n",
      "epoch 206 validation acc: 0.6759259\n",
      "Train Epoch: 207 [0%]\tLoss: 0.168271\n",
      "Train Epoch: 207 [93%]\tLoss: 0.523123\n",
      "epoch 207 training loss: 0.3295519781060176 acc: 0.8391608391608392\n",
      "epoch 207 validation acc: 0.5555556\n",
      "Train Epoch: 208 [0%]\tLoss: 0.207394\n",
      "Train Epoch: 208 [93%]\tLoss: 0.619270\n",
      "epoch 208 training loss: 0.34720143277405036 acc: 0.8508158508158508\n",
      "epoch 208 validation acc: 0.6944444\n",
      "Train Epoch: 209 [0%]\tLoss: 0.080005\n",
      "Train Epoch: 209 [93%]\tLoss: 0.252304\n",
      "epoch 209 training loss: 0.3160170234256872 acc: 0.8717948717948718\n",
      "epoch 209 validation acc: 0.537037\n",
      "Train Epoch: 210 [0%]\tLoss: 0.371364\n",
      "Train Epoch: 210 [93%]\tLoss: 1.310605\n",
      "epoch 210 training loss: 0.32139094082500647 acc: 0.8671328671328671\n",
      "epoch 210 validation acc: 0.5648148\n",
      "Train Epoch: 211 [0%]\tLoss: 0.530620\n",
      "Train Epoch: 211 [93%]\tLoss: 0.109874\n",
      "epoch 211 training loss: 0.35624850386132795 acc: 0.8484848484848485\n",
      "epoch 211 validation acc: 0.6944444\n",
      "Train Epoch: 212 [0%]\tLoss: 0.060234\n",
      "Train Epoch: 212 [93%]\tLoss: 0.896757\n",
      "epoch 212 training loss: 0.3426133323357337 acc: 0.8344988344988346\n",
      "epoch 212 validation acc: 0.537037\n",
      "Train Epoch: 213 [0%]\tLoss: 0.574428\n",
      "Train Epoch: 213 [93%]\tLoss: 0.490393\n",
      "epoch 213 training loss: 0.3339527800492727 acc: 0.8554778554778555\n",
      "epoch 213 validation acc: 0.6666667\n",
      "Train Epoch: 214 [0%]\tLoss: 0.128661\n",
      "Train Epoch: 214 [93%]\tLoss: 1.056558\n",
      "epoch 214 training loss: 0.3556723001367775 acc: 0.8508158508158508\n",
      "epoch 214 validation acc: 0.6666667\n",
      "Train Epoch: 215 [0%]\tLoss: 0.025846\n",
      "Train Epoch: 215 [93%]\tLoss: 0.016915\n",
      "epoch 215 training loss: 0.333263943512537 acc: 0.8391608391608392\n",
      "epoch 215 validation acc: 0.7407407\n",
      "Train Epoch: 216 [0%]\tLoss: 0.199807\n",
      "Train Epoch: 216 [93%]\tLoss: 0.910535\n",
      "epoch 216 training loss: 0.32360413565766066 acc: 0.8578088578088578\n",
      "epoch 216 validation acc: 0.6296296\n",
      "Train Epoch: 217 [0%]\tLoss: 0.107646\n",
      "Train Epoch: 217 [93%]\tLoss: 0.177267\n",
      "epoch 217 training loss: 0.3219431769835797 acc: 0.8671328671328671\n",
      "epoch 217 validation acc: 0.4814815\n",
      "Train Epoch: 218 [0%]\tLoss: 0.183539\n",
      "Train Epoch: 218 [93%]\tLoss: 0.780902\n",
      "epoch 218 training loss: 0.3522074017328797 acc: 0.8484848484848485\n",
      "epoch 218 validation acc: 0.6481481\n",
      "Train Epoch: 219 [0%]\tLoss: 0.487409\n",
      "Train Epoch: 219 [93%]\tLoss: 0.064939\n",
      "epoch 219 training loss: 0.35910033830441535 acc: 0.8484848484848485\n",
      "epoch 219 validation acc: 0.7037037\n",
      "Train Epoch: 220 [0%]\tLoss: 0.041759\n",
      "Train Epoch: 220 [93%]\tLoss: 0.578942\n",
      "epoch 220 training loss: 0.3257396936899534 acc: 0.8578088578088578\n",
      "epoch 220 validation acc: 0.5555556\n",
      "Train Epoch: 221 [0%]\tLoss: 0.090651\n",
      "Train Epoch: 221 [93%]\tLoss: 0.373606\n",
      "epoch 221 training loss: 0.33500111224269924 acc: 0.8508158508158508\n",
      "epoch 221 validation acc: 0.6666667\n",
      "Train Epoch: 222 [0%]\tLoss: 0.331837\n",
      "Train Epoch: 222 [93%]\tLoss: 0.517140\n",
      "epoch 222 training loss: 0.29623219707691867 acc: 0.8787878787878788\n",
      "epoch 222 validation acc: 0.6388889\n",
      "Train Epoch: 223 [0%]\tLoss: 0.232246\n",
      "Train Epoch: 223 [93%]\tLoss: 0.568823\n",
      "epoch 223 training loss: 0.33334656844467475 acc: 0.8391608391608392\n",
      "epoch 223 validation acc: 0.5925926\n",
      "Train Epoch: 224 [0%]\tLoss: 0.258496\n",
      "Train Epoch: 224 [93%]\tLoss: 0.361725\n",
      "epoch 224 training loss: 0.3447749263400005 acc: 0.8414918414918415\n",
      "epoch 224 validation acc: 0.6481481\n",
      "Train Epoch: 225 [0%]\tLoss: 0.299263\n",
      "Train Epoch: 225 [93%]\tLoss: 0.111815\n",
      "epoch 225 training loss: 0.3147794433645214 acc: 0.8648018648018648\n",
      "epoch 225 validation acc: 0.6111111\n",
      "Train Epoch: 226 [0%]\tLoss: 0.436711\n",
      "Train Epoch: 226 [93%]\tLoss: 0.017171\n",
      "epoch 226 training loss: 0.3365796769864607 acc: 0.8601398601398601\n",
      "epoch 226 validation acc: 0.5833333\n",
      "Train Epoch: 227 [0%]\tLoss: 0.364151\n",
      "Train Epoch: 227 [93%]\tLoss: 0.381416\n",
      "epoch 227 training loss: 0.32235006121724535 acc: 0.8671328671328671\n",
      "epoch 227 validation acc: 0.6574074\n",
      "Train Epoch: 228 [0%]\tLoss: 0.584689\n",
      "Train Epoch: 228 [93%]\tLoss: 0.044705\n",
      "epoch 228 training loss: 0.3356962456643857 acc: 0.8554778554778555\n",
      "epoch 228 validation acc: 0.6851852\n",
      "Train Epoch: 229 [0%]\tLoss: 0.651601\n",
      "Train Epoch: 229 [93%]\tLoss: 1.014539\n",
      "epoch 229 training loss: 0.3083666178734145 acc: 0.8601398601398601\n",
      "epoch 229 validation acc: 0.5648148\n",
      "Train Epoch: 230 [0%]\tLoss: 0.089139\n",
      "Train Epoch: 230 [93%]\tLoss: 1.423639\n",
      "epoch 230 training loss: 0.3176126868326079 acc: 0.8554778554778555\n",
      "epoch 230 validation acc: 0.6759259\n",
      "Train Epoch: 231 [0%]\tLoss: 0.872389\n",
      "Train Epoch: 231 [93%]\tLoss: 0.719020\n",
      "epoch 231 training loss: 0.36087959949185866 acc: 0.8368298368298368\n",
      "epoch 231 validation acc: 0.5648148\n",
      "Train Epoch: 232 [0%]\tLoss: 0.518870\n",
      "Train Epoch: 232 [93%]\tLoss: 0.123209\n",
      "epoch 232 training loss: 0.3221909571266561 acc: 0.8508158508158508\n",
      "epoch 232 validation acc: 0.6296296\n",
      "Train Epoch: 233 [0%]\tLoss: 0.234433\n",
      "Train Epoch: 233 [93%]\tLoss: 0.436538\n",
      "epoch 233 training loss: 0.33724872356591123 acc: 0.8648018648018648\n",
      "epoch 233 validation acc: 0.5648148\n",
      "Train Epoch: 234 [0%]\tLoss: 0.247956\n",
      "Train Epoch: 234 [93%]\tLoss: 0.129992\n",
      "epoch 234 training loss: 0.33485270195847583 acc: 0.8414918414918415\n",
      "epoch 234 validation acc: 0.6296296\n",
      "Train Epoch: 235 [0%]\tLoss: 0.052171\n",
      "Train Epoch: 235 [93%]\tLoss: 0.914872\n",
      "epoch 235 training loss: 0.36149758128104387 acc: 0.8414918414918415\n",
      "epoch 235 validation acc: 0.6203704\n",
      "Train Epoch: 236 [0%]\tLoss: 0.257748\n",
      "Train Epoch: 236 [93%]\tLoss: 0.186876\n",
      "epoch 236 training loss: 0.36628247578887063 acc: 0.8554778554778555\n",
      "epoch 236 validation acc: 0.712963\n",
      "Train Epoch: 237 [0%]\tLoss: 0.072667\n",
      "Train Epoch: 237 [93%]\tLoss: 0.293785\n",
      "epoch 237 training loss: 0.31824576006167465 acc: 0.8648018648018648\n",
      "epoch 237 validation acc: 0.6759259\n",
      "Train Epoch: 238 [0%]\tLoss: 0.404112\n",
      "Train Epoch: 238 [93%]\tLoss: 0.143313\n",
      "epoch 238 training loss: 0.3441718986809806 acc: 0.8648018648018648\n",
      "epoch 238 validation acc: 0.6296296\n",
      "Train Epoch: 239 [0%]\tLoss: 0.382558\n",
      "Train Epoch: 239 [93%]\tLoss: 0.686804\n",
      "epoch 239 training loss: 0.31109137536986964 acc: 0.8554778554778555\n",
      "epoch 239 validation acc: 0.6296296\n",
      "Train Epoch: 240 [0%]\tLoss: 0.649282\n",
      "Train Epoch: 240 [93%]\tLoss: 0.124320\n",
      "epoch 240 training loss: 0.343037406083938 acc: 0.8321678321678322\n",
      "epoch 240 validation acc: 0.75\n",
      "Train Epoch: 241 [0%]\tLoss: 0.064939\n",
      "Train Epoch: 241 [93%]\tLoss: 0.367688\n",
      "epoch 241 training loss: 0.36817162915098445 acc: 0.8321678321678322\n",
      "epoch 241 validation acc: 0.7222222\n",
      "Train Epoch: 242 [0%]\tLoss: 0.132713\n",
      "Train Epoch: 242 [93%]\tLoss: 0.163401\n",
      "epoch 242 training loss: 0.3049643925235917 acc: 0.8741258741258742\n",
      "epoch 242 validation acc: 0.6944444\n",
      "Train Epoch: 243 [0%]\tLoss: 0.354526\n",
      "Train Epoch: 243 [93%]\tLoss: 0.098241\n",
      "epoch 243 training loss: 0.3085918291428782 acc: 0.8787878787878788\n",
      "epoch 243 validation acc: 0.5277778\n",
      "Train Epoch: 244 [0%]\tLoss: 0.613551\n",
      "Train Epoch: 244 [93%]\tLoss: 0.629198\n",
      "epoch 244 training loss: 0.30545514622159925 acc: 0.8741258741258742\n",
      "epoch 244 validation acc: 0.6111111\n",
      "Train Epoch: 245 [0%]\tLoss: 0.208896\n",
      "Train Epoch: 245 [93%]\tLoss: 0.198250\n",
      "epoch 245 training loss: 0.3216248076717387 acc: 0.8648018648018648\n",
      "epoch 245 validation acc: 0.6018519\n",
      "Train Epoch: 246 [0%]\tLoss: 0.422921\n",
      "Train Epoch: 246 [93%]\tLoss: 0.534662\n",
      "epoch 246 training loss: 0.3266095081631243 acc: 0.8438228438228438\n",
      "epoch 246 validation acc: 0.6574074\n",
      "Train Epoch: 247 [0%]\tLoss: 0.333744\n",
      "Train Epoch: 247 [93%]\tLoss: 0.218291\n",
      "epoch 247 training loss: 0.34024848224146775 acc: 0.8344988344988346\n",
      "epoch 247 validation acc: 0.5185185\n",
      "Train Epoch: 248 [0%]\tLoss: 0.295892\n",
      "Train Epoch: 248 [93%]\tLoss: 0.168187\n",
      "epoch 248 training loss: 0.3432486189563793 acc: 0.8321678321678322\n",
      "epoch 248 validation acc: 0.5555556\n",
      "Train Epoch: 249 [0%]\tLoss: 0.085593\n",
      "Train Epoch: 249 [93%]\tLoss: 0.476214\n",
      "epoch 249 training loss: 0.35287969969902877 acc: 0.8554778554778555\n",
      "epoch 249 validation acc: 0.6759259\n",
      "Train Epoch: 250 [0%]\tLoss: 0.126569\n",
      "Train Epoch: 250 [93%]\tLoss: 0.081214\n",
      "epoch 250 training loss: 0.290161042866573 acc: 0.8787878787878788\n",
      "epoch 250 validation acc: 0.5740741\n",
      "Train Epoch: 251 [0%]\tLoss: 0.504185\n",
      "Train Epoch: 251 [93%]\tLoss: 0.282546\n",
      "epoch 251 training loss: 0.34171774933282806 acc: 0.8438228438228438\n",
      "epoch 251 validation acc: 0.5462963\n",
      "Train Epoch: 252 [0%]\tLoss: 0.294959\n",
      "Train Epoch: 252 [93%]\tLoss: 0.227714\n",
      "epoch 252 training loss: 0.314545310775025 acc: 0.8601398601398601\n",
      "epoch 252 validation acc: 0.6574074\n",
      "Train Epoch: 253 [0%]\tLoss: 0.215454\n",
      "Train Epoch: 253 [93%]\tLoss: 0.357698\n",
      "epoch 253 training loss: 0.35353496831548575 acc: 0.8624708624708625\n",
      "epoch 253 validation acc: 0.6481481\n",
      "Train Epoch: 254 [0%]\tLoss: 0.219793\n",
      "Train Epoch: 254 [93%]\tLoss: 0.665895\n",
      "epoch 254 training loss: 0.3379996427403832 acc: 0.8531468531468531\n",
      "epoch 254 validation acc: 0.6481481\n",
      "Train Epoch: 255 [0%]\tLoss: 0.232359\n",
      "Train Epoch: 255 [93%]\tLoss: 0.103883\n",
      "epoch 255 training loss: 0.3168375927661718 acc: 0.8648018648018648\n",
      "epoch 255 validation acc: 0.5277778\n",
      "Train Epoch: 256 [0%]\tLoss: 0.207944\n",
      "Train Epoch: 256 [93%]\tLoss: 0.123773\n",
      "epoch 256 training loss: 0.31512383797585414 acc: 0.8694638694638694\n",
      "epoch 256 validation acc: 0.6296296\n",
      "Train Epoch: 257 [0%]\tLoss: 0.658459\n",
      "Train Epoch: 257 [93%]\tLoss: 0.204499\n",
      "epoch 257 training loss: 0.30310632892090966 acc: 0.8717948717948718\n",
      "epoch 257 validation acc: 0.5555556\n",
      "Train Epoch: 258 [0%]\tLoss: 0.664706\n",
      "Train Epoch: 258 [93%]\tLoss: 0.073630\n",
      "epoch 258 training loss: 0.31935962249257566 acc: 0.8648018648018648\n",
      "epoch 258 validation acc: 0.6666667\n",
      "Train Epoch: 259 [0%]\tLoss: 0.132260\n",
      "Train Epoch: 259 [93%]\tLoss: 0.602924\n",
      "epoch 259 training loss: 0.3272826669530736 acc: 0.8624708624708625\n",
      "epoch 259 validation acc: 0.6666667\n",
      "Train Epoch: 260 [0%]\tLoss: 0.029245\n",
      "Train Epoch: 260 [93%]\tLoss: 0.232244\n",
      "epoch 260 training loss: 0.3357718780413658 acc: 0.8624708624708625\n",
      "epoch 260 validation acc: 0.6666667\n",
      "Train Epoch: 261 [0%]\tLoss: 0.029763\n",
      "Train Epoch: 261 [93%]\tLoss: 0.271666\n",
      "epoch 261 training loss: 0.3188690234916673 acc: 0.8508158508158508\n",
      "epoch 261 validation acc: 0.6111111\n",
      "Train Epoch: 262 [0%]\tLoss: 0.453888\n",
      "Train Epoch: 262 [93%]\tLoss: 0.737740\n",
      "epoch 262 training loss: 0.3139319644930462 acc: 0.8648018648018648\n",
      "epoch 262 validation acc: 0.5833333\n",
      "Train Epoch: 263 [0%]\tLoss: 0.140253\n",
      "Train Epoch: 263 [93%]\tLoss: 0.252651\n",
      "epoch 263 training loss: 0.32298471259195205 acc: 0.8554778554778555\n",
      "epoch 263 validation acc: 0.6481481\n",
      "Train Epoch: 264 [0%]\tLoss: 0.408785\n",
      "Train Epoch: 264 [93%]\tLoss: 0.270692\n",
      "epoch 264 training loss: 0.37599230662885086 acc: 0.8484848484848485\n",
      "epoch 264 validation acc: 0.6296296\n",
      "Train Epoch: 265 [0%]\tLoss: 0.133203\n",
      "Train Epoch: 265 [93%]\tLoss: 0.596422\n",
      "epoch 265 training loss: 0.32392574701872134 acc: 0.8648018648018648\n",
      "epoch 265 validation acc: 0.6018519\n",
      "Train Epoch: 266 [0%]\tLoss: 0.189202\n",
      "Train Epoch: 266 [93%]\tLoss: 0.277793\n",
      "epoch 266 training loss: 0.31574198063415476 acc: 0.8648018648018648\n",
      "epoch 266 validation acc: 0.6203704\n",
      "Train Epoch: 267 [0%]\tLoss: 0.464643\n",
      "Train Epoch: 267 [93%]\tLoss: 0.313354\n",
      "epoch 267 training loss: 0.2941567426530161 acc: 0.8764568764568764\n",
      "epoch 267 validation acc: 0.5092593\n",
      "Train Epoch: 268 [0%]\tLoss: 0.102250\n",
      "Train Epoch: 268 [93%]\tLoss: 0.170930\n",
      "epoch 268 training loss: 0.29106512215609354 acc: 0.8671328671328671\n",
      "epoch 268 validation acc: 0.537037\n",
      "Train Epoch: 269 [0%]\tLoss: 0.215709\n",
      "Train Epoch: 269 [93%]\tLoss: 0.901669\n",
      "epoch 269 training loss: 0.30190621839439563 acc: 0.8648018648018648\n",
      "epoch 269 validation acc: 0.6111111\n",
      "Train Epoch: 270 [0%]\tLoss: 0.159201\n",
      "Train Epoch: 270 [93%]\tLoss: 0.549798\n",
      "epoch 270 training loss: 0.3566156206221354 acc: 0.8298368298368298\n",
      "epoch 270 validation acc: 0.5833333\n",
      "Train Epoch: 271 [0%]\tLoss: 0.042274\n",
      "Train Epoch: 271 [93%]\tLoss: 0.169305\n",
      "epoch 271 training loss: 0.3316737679911225 acc: 0.8484848484848485\n",
      "epoch 271 validation acc: 0.5925926\n",
      "Train Epoch: 272 [0%]\tLoss: 0.191858\n",
      "Train Epoch: 272 [93%]\tLoss: 0.651387\n",
      "epoch 272 training loss: 0.3062871186983237 acc: 0.8554778554778555\n",
      "epoch 272 validation acc: 0.712963\n",
      "Train Epoch: 273 [0%]\tLoss: 0.836884\n",
      "Train Epoch: 273 [93%]\tLoss: 0.557108\n",
      "epoch 273 training loss: 0.34901300767712573 acc: 0.8484848484848485\n",
      "epoch 273 validation acc: 0.6481481\n",
      "Train Epoch: 274 [0%]\tLoss: 0.147027\n",
      "Train Epoch: 274 [93%]\tLoss: 0.116657\n",
      "epoch 274 training loss: 0.30085496679816126 acc: 0.8671328671328671\n",
      "epoch 274 validation acc: 0.7314815\n",
      "Train Epoch: 275 [0%]\tLoss: 0.216428\n",
      "Train Epoch: 275 [93%]\tLoss: 0.271592\n",
      "epoch 275 training loss: 0.32158229604397937 acc: 0.8648018648018648\n",
      "epoch 275 validation acc: 0.7037037\n",
      "Train Epoch: 276 [0%]\tLoss: 0.222368\n",
      "Train Epoch: 276 [93%]\tLoss: 0.269574\n",
      "epoch 276 training loss: 0.3081575568013014 acc: 0.8648018648018648\n",
      "epoch 276 validation acc: 0.4722222\n",
      "Train Epoch: 277 [0%]\tLoss: 0.042413\n",
      "Train Epoch: 277 [93%]\tLoss: 0.659058\n",
      "epoch 277 training loss: 0.3355342014954119 acc: 0.8368298368298368\n",
      "epoch 277 validation acc: 0.5833333\n",
      "Train Epoch: 278 [0%]\tLoss: 0.098599\n",
      "Train Epoch: 278 [93%]\tLoss: 0.187379\n",
      "epoch 278 training loss: 0.3052261173628115 acc: 0.8764568764568764\n",
      "epoch 278 validation acc: 0.5833333\n",
      "Train Epoch: 279 [0%]\tLoss: 0.034409\n",
      "Train Epoch: 279 [93%]\tLoss: 0.144188\n",
      "epoch 279 training loss: 0.3287539473558017 acc: 0.8461538461538461\n",
      "epoch 279 validation acc: 0.6851852\n",
      "Train Epoch: 280 [0%]\tLoss: 0.153752\n",
      "Train Epoch: 280 [93%]\tLoss: 0.721180\n",
      "epoch 280 training loss: 0.3148311427104528 acc: 0.8461538461538461\n",
      "epoch 280 validation acc: 0.6203704\n",
      "Train Epoch: 281 [0%]\tLoss: 0.351420\n",
      "Train Epoch: 281 [93%]\tLoss: 0.040131\n",
      "epoch 281 training loss: 0.29278052377480046 acc: 0.8648018648018648\n",
      "epoch 281 validation acc: 0.49074075\n",
      "Train Epoch: 282 [0%]\tLoss: 0.133678\n",
      "Train Epoch: 282 [93%]\tLoss: 0.488281\n",
      "epoch 282 training loss: 0.3172237575401798 acc: 0.8554778554778555\n",
      "epoch 282 validation acc: 0.6111111\n",
      "Train Epoch: 283 [0%]\tLoss: 0.123389\n",
      "Train Epoch: 283 [93%]\tLoss: 0.520808\n",
      "epoch 283 training loss: 0.3209113398204661 acc: 0.8624708624708625\n",
      "epoch 283 validation acc: 0.6851852\n",
      "Train Epoch: 284 [0%]\tLoss: 0.157880\n",
      "Train Epoch: 284 [93%]\tLoss: 0.498445\n",
      "epoch 284 training loss: 0.3326580611993214 acc: 0.8344988344988346\n",
      "epoch 284 validation acc: 0.5462963\n",
      "Train Epoch: 285 [0%]\tLoss: 0.128737\n",
      "Train Epoch: 285 [93%]\tLoss: 0.069027\n",
      "epoch 285 training loss: 0.31931614640375805 acc: 0.8624708624708625\n",
      "epoch 285 validation acc: 0.5277778\n",
      "Train Epoch: 286 [0%]\tLoss: 0.166619\n",
      "Train Epoch: 286 [93%]\tLoss: 0.031046\n",
      "epoch 286 training loss: 0.3153675146081864 acc: 0.8648018648018648\n",
      "epoch 286 validation acc: 0.6296296\n",
      "Train Epoch: 287 [0%]\tLoss: 0.041115\n",
      "Train Epoch: 287 [93%]\tLoss: 0.301803\n",
      "epoch 287 training loss: 0.319500525266415 acc: 0.8578088578088578\n",
      "epoch 287 validation acc: 0.5555556\n",
      "Train Epoch: 288 [0%]\tLoss: 0.338258\n",
      "Train Epoch: 288 [93%]\tLoss: 0.210727\n",
      "epoch 288 training loss: 0.30403352100809033 acc: 0.8717948717948718\n",
      "epoch 288 validation acc: 0.6296296\n",
      "Train Epoch: 289 [0%]\tLoss: 0.365404\n",
      "Train Epoch: 289 [93%]\tLoss: 0.151867\n",
      "epoch 289 training loss: 0.31305414540865634 acc: 0.8741258741258742\n",
      "epoch 289 validation acc: 0.6759259\n",
      "Train Epoch: 290 [0%]\tLoss: 0.136256\n",
      "Train Epoch: 290 [93%]\tLoss: 0.230152\n",
      "epoch 290 training loss: 0.30769121885640305 acc: 0.8904428904428905\n",
      "epoch 290 validation acc: 0.7314815\n",
      "Train Epoch: 291 [0%]\tLoss: 0.145064\n",
      "Train Epoch: 291 [93%]\tLoss: 0.037876\n",
      "epoch 291 training loss: 0.34156259804688116 acc: 0.8484848484848485\n",
      "epoch 291 validation acc: 0.7037037\n",
      "Train Epoch: 292 [0%]\tLoss: 0.234975\n",
      "Train Epoch: 292 [93%]\tLoss: 0.951281\n",
      "epoch 292 training loss: 0.30053292284719646 acc: 0.8601398601398601\n",
      "epoch 292 validation acc: 0.6296296\n",
      "Train Epoch: 293 [0%]\tLoss: 0.402763\n",
      "Train Epoch: 293 [93%]\tLoss: 0.291469\n",
      "epoch 293 training loss: 0.3027369509951246 acc: 0.8531468531468531\n",
      "epoch 293 validation acc: 0.537037\n",
      "Train Epoch: 294 [0%]\tLoss: 0.714887\n",
      "Train Epoch: 294 [93%]\tLoss: 0.137311\n",
      "epoch 294 training loss: 0.3197301981242533 acc: 0.8671328671328671\n",
      "epoch 294 validation acc: 0.6851852\n",
      "Train Epoch: 295 [0%]\tLoss: 0.107286\n",
      "Train Epoch: 295 [93%]\tLoss: 0.070006\n",
      "epoch 295 training loss: 0.32668782738727276 acc: 0.8414918414918415\n",
      "epoch 295 validation acc: 0.5555556\n",
      "Train Epoch: 296 [0%]\tLoss: 0.235550\n",
      "Train Epoch: 296 [93%]\tLoss: 0.107990\n",
      "epoch 296 training loss: 0.38853958285310203 acc: 0.8368298368298368\n",
      "epoch 296 validation acc: 0.6111111\n",
      "Train Epoch: 297 [0%]\tLoss: 0.069831\n",
      "Train Epoch: 297 [93%]\tLoss: 0.274428\n",
      "epoch 297 training loss: 0.3142590183267236 acc: 0.8601398601398601\n",
      "epoch 297 validation acc: 0.5833333\n",
      "Train Epoch: 298 [0%]\tLoss: 0.132654\n",
      "Train Epoch: 298 [93%]\tLoss: 0.238274\n",
      "epoch 298 training loss: 0.2964062023114551 acc: 0.8811188811188811\n",
      "epoch 298 validation acc: 0.6203704\n",
      "Train Epoch: 299 [0%]\tLoss: 0.433616\n",
      "Train Epoch: 299 [93%]\tLoss: 0.126741\n",
      "epoch 299 training loss: 0.34158136309728165 acc: 0.8601398601398601\n",
      "epoch 299 validation acc: 0.5555556\n",
      "Train Epoch: 300 [0%]\tLoss: 0.060037\n",
      "Train Epoch: 300 [93%]\tLoss: 0.546023\n",
      "epoch 300 training loss: 0.2923323563127606 acc: 0.8671328671328671\n",
      "epoch 300 validation acc: 0.5925926\n",
      "Train Epoch: 301 [0%]\tLoss: 0.171125\n",
      "Train Epoch: 301 [93%]\tLoss: 0.917672\n",
      "epoch 301 training loss: 0.26613858541370267 acc: 0.8834498834498834\n",
      "epoch 301 validation acc: 0.6203704\n",
      "Train Epoch: 302 [0%]\tLoss: 0.272877\n",
      "Train Epoch: 302 [93%]\tLoss: 0.268399\n",
      "epoch 302 training loss: 0.29059129146022583 acc: 0.8741258741258742\n",
      "epoch 302 validation acc: 0.6851852\n",
      "Train Epoch: 303 [0%]\tLoss: 0.020439\n",
      "Train Epoch: 303 [93%]\tLoss: 0.277582\n",
      "epoch 303 training loss: 0.3001968189854341 acc: 0.8741258741258742\n",
      "epoch 303 validation acc: 0.6666667\n",
      "Train Epoch: 304 [0%]\tLoss: 0.347825\n",
      "Train Epoch: 304 [93%]\tLoss: 0.416894\n",
      "epoch 304 training loss: 0.32160827282954146 acc: 0.8671328671328671\n",
      "epoch 304 validation acc: 0.5555556\n",
      "Train Epoch: 305 [0%]\tLoss: 0.051301\n",
      "Train Epoch: 305 [93%]\tLoss: 0.142477\n",
      "epoch 305 training loss: 0.33753125876602197 acc: 0.8438228438228438\n",
      "epoch 305 validation acc: 0.537037\n",
      "Train Epoch: 306 [0%]\tLoss: 0.063036\n",
      "Train Epoch: 306 [93%]\tLoss: 0.286311\n",
      "epoch 306 training loss: 0.27577463744415176 acc: 0.8717948717948718\n",
      "epoch 306 validation acc: 0.5\n",
      "Train Epoch: 307 [0%]\tLoss: 0.244527\n",
      "Train Epoch: 307 [93%]\tLoss: 0.167029\n",
      "epoch 307 training loss: 0.3139093840425765 acc: 0.8601398601398601\n",
      "epoch 307 validation acc: 0.6388889\n",
      "Train Epoch: 308 [0%]\tLoss: 1.244275\n",
      "Train Epoch: 308 [93%]\tLoss: 0.239139\n",
      "epoch 308 training loss: 0.2902003511974019 acc: 0.8648018648018648\n",
      "epoch 308 validation acc: 0.7037037\n",
      "Train Epoch: 309 [0%]\tLoss: 0.031231\n",
      "Train Epoch: 309 [93%]\tLoss: 0.167942\n",
      "epoch 309 training loss: 0.2820679430194475 acc: 0.8904428904428905\n",
      "epoch 309 validation acc: 0.6481481\n",
      "Train Epoch: 310 [0%]\tLoss: 0.516908\n",
      "Train Epoch: 310 [93%]\tLoss: 0.151388\n",
      "epoch 310 training loss: 0.3256044977396313 acc: 0.8578088578088578\n",
      "epoch 310 validation acc: 0.6111111\n",
      "Train Epoch: 311 [0%]\tLoss: 0.353242\n",
      "Train Epoch: 311 [93%]\tLoss: 0.420806\n",
      "epoch 311 training loss: 0.3114633974101808 acc: 0.8648018648018648\n",
      "epoch 311 validation acc: 0.6018519\n",
      "Train Epoch: 312 [0%]\tLoss: 0.451078\n",
      "Train Epoch: 312 [93%]\tLoss: 0.124327\n",
      "epoch 312 training loss: 0.29989438754057995 acc: 0.8648018648018648\n",
      "epoch 312 validation acc: 0.6481481\n",
      "Train Epoch: 313 [0%]\tLoss: 0.196640\n",
      "Train Epoch: 313 [93%]\tLoss: 0.097955\n",
      "epoch 313 training loss: 0.27571914019602073 acc: 0.8624708624708625\n",
      "epoch 313 validation acc: 0.6018519\n",
      "Train Epoch: 314 [0%]\tLoss: 0.295063\n",
      "Train Epoch: 314 [93%]\tLoss: 0.824637\n",
      "epoch 314 training loss: 0.31514919672971936 acc: 0.8554778554778555\n",
      "epoch 314 validation acc: 0.6481481\n",
      "Train Epoch: 315 [0%]\tLoss: 0.310497\n",
      "Train Epoch: 315 [93%]\tLoss: 0.636345\n",
      "epoch 315 training loss: 0.2924850546168508 acc: 0.8717948717948718\n",
      "epoch 315 validation acc: 0.5462963\n",
      "Train Epoch: 316 [0%]\tLoss: 0.118252\n",
      "Train Epoch: 316 [93%]\tLoss: 0.145976\n",
      "epoch 316 training loss: 0.3198065135360661 acc: 0.8484848484848485\n",
      "epoch 316 validation acc: 0.5740741\n",
      "Train Epoch: 317 [0%]\tLoss: 0.396366\n",
      "Train Epoch: 317 [93%]\tLoss: 0.517897\n",
      "epoch 317 training loss: 0.2889650648770233 acc: 0.8694638694638694\n",
      "epoch 317 validation acc: 0.6574074\n",
      "Train Epoch: 318 [0%]\tLoss: 0.011284\n",
      "Train Epoch: 318 [93%]\tLoss: 0.103388\n",
      "epoch 318 training loss: 0.31280680538017164 acc: 0.8531468531468531\n",
      "epoch 318 validation acc: 0.537037\n",
      "Train Epoch: 319 [0%]\tLoss: 0.303814\n",
      "Train Epoch: 319 [93%]\tLoss: 0.111654\n",
      "epoch 319 training loss: 0.2777185672786328 acc: 0.8717948717948718\n",
      "epoch 319 validation acc: 0.712963\n",
      "Train Epoch: 320 [0%]\tLoss: 0.063563\n",
      "Train Epoch: 320 [93%]\tLoss: 0.287145\n",
      "epoch 320 training loss: 0.28592935855569385 acc: 0.8811188811188811\n",
      "epoch 320 validation acc: 0.6111111\n",
      "Train Epoch: 321 [0%]\tLoss: 0.562912\n",
      "Train Epoch: 321 [93%]\tLoss: 0.165607\n",
      "epoch 321 training loss: 0.3204714051378822 acc: 0.8531468531468531\n",
      "epoch 321 validation acc: 0.6574074\n",
      "Train Epoch: 322 [0%]\tLoss: 0.099337\n",
      "Train Epoch: 322 [93%]\tLoss: 0.490980\n",
      "epoch 322 training loss: 0.29364213099944647 acc: 0.8787878787878788\n",
      "epoch 322 validation acc: 0.5833333\n",
      "Train Epoch: 323 [0%]\tLoss: 0.156228\n",
      "Train Epoch: 323 [93%]\tLoss: 0.035826\n",
      "epoch 323 training loss: 0.2961050487377819 acc: 0.8694638694638694\n",
      "epoch 323 validation acc: 0.5648148\n",
      "Train Epoch: 324 [0%]\tLoss: 0.201031\n",
      "Train Epoch: 324 [93%]\tLoss: 0.253680\n",
      "epoch 324 training loss: 0.2901267437867958 acc: 0.8834498834498834\n",
      "epoch 324 validation acc: 0.6666667\n",
      "Train Epoch: 325 [0%]\tLoss: 0.508601\n",
      "Train Epoch: 325 [93%]\tLoss: 0.746415\n",
      "epoch 325 training loss: 0.32259371219616795 acc: 0.8414918414918415\n",
      "epoch 325 validation acc: 0.6296296\n",
      "Train Epoch: 326 [0%]\tLoss: 0.216162\n",
      "Train Epoch: 326 [93%]\tLoss: 0.100721\n",
      "epoch 326 training loss: 0.2731163949615115 acc: 0.8717948717948718\n",
      "epoch 326 validation acc: 0.5462963\n",
      "Train Epoch: 327 [0%]\tLoss: 0.059951\n",
      "Train Epoch: 327 [93%]\tLoss: 0.554976\n",
      "epoch 327 training loss: 0.29665140024196635 acc: 0.8741258741258742\n",
      "epoch 327 validation acc: 0.5185185\n",
      "Train Epoch: 328 [0%]\tLoss: 0.109847\n",
      "Train Epoch: 328 [93%]\tLoss: 0.087477\n",
      "epoch 328 training loss: 0.3174889889304285 acc: 0.8531468531468531\n",
      "epoch 328 validation acc: 0.5462963\n",
      "Train Epoch: 329 [0%]\tLoss: 0.073528\n",
      "Train Epoch: 329 [93%]\tLoss: 0.990909\n",
      "epoch 329 training loss: 0.3180893380166607 acc: 0.8741258741258742\n",
      "epoch 329 validation acc: 0.6203704\n",
      "Train Epoch: 330 [0%]\tLoss: 0.071869\n",
      "Train Epoch: 330 [93%]\tLoss: 0.096240\n",
      "epoch 330 training loss: 0.33077462630656856 acc: 0.8531468531468531\n",
      "epoch 330 validation acc: 0.5740741\n",
      "Train Epoch: 331 [0%]\tLoss: 0.228561\n",
      "Train Epoch: 331 [93%]\tLoss: 0.343428\n",
      "epoch 331 training loss: 0.2996949207887088 acc: 0.8484848484848485\n",
      "epoch 331 validation acc: 0.5\n",
      "Train Epoch: 332 [0%]\tLoss: 0.154292\n",
      "Train Epoch: 332 [93%]\tLoss: 0.554926\n",
      "epoch 332 training loss: 0.3577230468379437 acc: 0.8344988344988346\n",
      "epoch 332 validation acc: 0.5925926\n",
      "Train Epoch: 333 [0%]\tLoss: 0.188088\n",
      "Train Epoch: 333 [93%]\tLoss: 0.260063\n",
      "epoch 333 training loss: 0.3075966275861935 acc: 0.8811188811188811\n",
      "epoch 333 validation acc: 0.5555556\n",
      "Train Epoch: 334 [0%]\tLoss: 0.360665\n",
      "Train Epoch: 334 [93%]\tLoss: 0.879683\n",
      "epoch 334 training loss: 0.31513925268491555 acc: 0.8601398601398601\n",
      "epoch 334 validation acc: 0.6296296\n",
      "Train Epoch: 335 [0%]\tLoss: 0.232558\n",
      "Train Epoch: 335 [93%]\tLoss: 0.085896\n",
      "epoch 335 training loss: 0.2933237805738355 acc: 0.8811188811188811\n",
      "epoch 335 validation acc: 0.5740741\n",
      "Train Epoch: 336 [0%]\tLoss: 0.070744\n",
      "Train Epoch: 336 [93%]\tLoss: 0.321863\n",
      "epoch 336 training loss: 0.30226067595638734 acc: 0.8787878787878788\n",
      "epoch 336 validation acc: 0.6111111\n",
      "Train Epoch: 337 [0%]\tLoss: 0.246844\n",
      "Train Epoch: 337 [93%]\tLoss: 0.145759\n",
      "epoch 337 training loss: 0.29791078373199087 acc: 0.8811188811188811\n",
      "epoch 337 validation acc: 0.6018519\n",
      "Train Epoch: 338 [0%]\tLoss: 0.301334\n",
      "Train Epoch: 338 [93%]\tLoss: 0.376464\n",
      "epoch 338 training loss: 0.33568159973866485 acc: 0.8414918414918415\n",
      "epoch 338 validation acc: 0.7592593\n",
      "Train Epoch: 339 [0%]\tLoss: 0.106738\n",
      "Train Epoch: 339 [93%]\tLoss: 0.754683\n",
      "epoch 339 training loss: 0.2931509723485861 acc: 0.8764568764568764\n",
      "epoch 339 validation acc: 0.6574074\n",
      "Train Epoch: 340 [0%]\tLoss: 0.618304\n",
      "Train Epoch: 340 [93%]\tLoss: 0.403318\n",
      "epoch 340 training loss: 0.335002861002943 acc: 0.8438228438228438\n",
      "epoch 340 validation acc: 0.712963\n",
      "Train Epoch: 341 [0%]\tLoss: 0.973297\n",
      "Train Epoch: 341 [93%]\tLoss: 0.152687\n",
      "epoch 341 training loss: 0.31436995760520436 acc: 0.8671328671328671\n",
      "epoch 341 validation acc: 0.5648148\n",
      "Train Epoch: 342 [0%]\tLoss: 0.853883\n",
      "Train Epoch: 342 [93%]\tLoss: 0.053481\n",
      "epoch 342 training loss: 0.2970218420668971 acc: 0.8741258741258742\n",
      "epoch 342 validation acc: 0.6481481\n",
      "Train Epoch: 343 [0%]\tLoss: 0.417392\n",
      "Train Epoch: 343 [93%]\tLoss: 0.562823\n",
      "epoch 343 training loss: 0.2598395407786248 acc: 0.8834498834498834\n",
      "epoch 343 validation acc: 0.6574074\n",
      "Train Epoch: 344 [0%]\tLoss: 0.370852\n",
      "Train Epoch: 344 [93%]\tLoss: 0.426948\n",
      "epoch 344 training loss: 0.31605627746924897 acc: 0.8741258741258742\n",
      "epoch 344 validation acc: 0.5555556\n",
      "Train Epoch: 345 [0%]\tLoss: 0.617981\n",
      "Train Epoch: 345 [93%]\tLoss: 0.167436\n",
      "epoch 345 training loss: 0.32197515078371874 acc: 0.8601398601398601\n",
      "epoch 345 validation acc: 0.5833333\n",
      "Train Epoch: 346 [0%]\tLoss: 0.726428\n",
      "Train Epoch: 346 [93%]\tLoss: 0.065091\n",
      "epoch 346 training loss: 0.2915343609466045 acc: 0.8578088578088578\n",
      "epoch 346 validation acc: 0.6203704\n",
      "Train Epoch: 347 [0%]\tLoss: 0.340611\n",
      "Train Epoch: 347 [93%]\tLoss: 0.533972\n",
      "epoch 347 training loss: 0.302963865200851 acc: 0.8671328671328671\n",
      "epoch 347 validation acc: 0.5277778\n",
      "Train Epoch: 348 [0%]\tLoss: 0.168287\n",
      "Train Epoch: 348 [93%]\tLoss: 0.517225\n",
      "epoch 348 training loss: 0.2853989472819699 acc: 0.8881118881118881\n",
      "epoch 348 validation acc: 0.6296296\n",
      "Train Epoch: 349 [0%]\tLoss: 0.016011\n",
      "Train Epoch: 349 [93%]\tLoss: 0.121022\n",
      "epoch 349 training loss: 0.2971814431129368 acc: 0.8811188811188811\n",
      "epoch 349 validation acc: 0.5185185\n",
      "Train Epoch: 350 [0%]\tLoss: 0.744973\n",
      "Train Epoch: 350 [93%]\tLoss: 0.460291\n",
      "epoch 350 training loss: 0.2701150025289583 acc: 0.8881118881118881\n",
      "epoch 350 validation acc: 0.4351852\n",
      "Train Epoch: 351 [0%]\tLoss: 0.068838\n",
      "Train Epoch: 351 [93%]\tLoss: 0.278291\n",
      "epoch 351 training loss: 0.3020950144812189 acc: 0.8811188811188811\n",
      "epoch 351 validation acc: 0.6296296\n",
      "Train Epoch: 352 [0%]\tLoss: 0.229399\n",
      "Train Epoch: 352 [93%]\tLoss: 0.379453\n",
      "epoch 352 training loss: 0.292013696955379 acc: 0.8834498834498834\n",
      "epoch 352 validation acc: 0.5\n",
      "Train Epoch: 353 [0%]\tLoss: 0.086467\n",
      "Train Epoch: 353 [93%]\tLoss: 0.338697\n",
      "epoch 353 training loss: 0.283799528831339 acc: 0.8741258741258742\n",
      "epoch 353 validation acc: 0.6018519\n",
      "Train Epoch: 354 [0%]\tLoss: 0.281642\n",
      "Train Epoch: 354 [93%]\tLoss: 1.110460\n",
      "epoch 354 training loss: 0.3014924279962762 acc: 0.8554778554778555\n",
      "epoch 354 validation acc: 0.5185185\n",
      "Train Epoch: 355 [0%]\tLoss: 0.322298\n",
      "Train Epoch: 355 [93%]\tLoss: 0.358085\n",
      "epoch 355 training loss: 0.30524219537835084 acc: 0.8624708624708625\n",
      "epoch 355 validation acc: 0.46296296\n",
      "Train Epoch: 356 [0%]\tLoss: 0.355300\n",
      "Train Epoch: 356 [93%]\tLoss: 0.362824\n",
      "epoch 356 training loss: 0.3266200975049287 acc: 0.8624708624708625\n",
      "epoch 356 validation acc: 0.5648148\n",
      "Train Epoch: 357 [0%]\tLoss: 0.031464\n",
      "Train Epoch: 357 [93%]\tLoss: 0.330893\n",
      "epoch 357 training loss: 0.2621745802720802 acc: 0.8857808857808858\n",
      "epoch 357 validation acc: 0.6388889\n",
      "Train Epoch: 358 [0%]\tLoss: 0.027668\n",
      "Train Epoch: 358 [93%]\tLoss: 0.081857\n",
      "epoch 358 training loss: 0.2993728160056182 acc: 0.8601398601398601\n",
      "epoch 358 validation acc: 0.5185185\n",
      "Train Epoch: 359 [0%]\tLoss: 0.840985\n",
      "Train Epoch: 359 [93%]\tLoss: 0.214027\n",
      "epoch 359 training loss: 0.2772226824610563 acc: 0.8601398601398601\n",
      "epoch 359 validation acc: 0.6018519\n",
      "Train Epoch: 360 [0%]\tLoss: 0.144700\n",
      "Train Epoch: 360 [93%]\tLoss: 0.425484\n",
      "epoch 360 training loss: 0.3066459666609902 acc: 0.8531468531468531\n",
      "epoch 360 validation acc: 0.5277778\n",
      "Train Epoch: 361 [0%]\tLoss: 0.344738\n",
      "Train Epoch: 361 [93%]\tLoss: 0.338711\n",
      "epoch 361 training loss: 0.27967051771890883 acc: 0.8904428904428905\n",
      "epoch 361 validation acc: 0.6296296\n",
      "Train Epoch: 362 [0%]\tLoss: 0.295335\n",
      "Train Epoch: 362 [93%]\tLoss: 0.021046\n",
      "epoch 362 training loss: 0.37195303751138487 acc: 0.8508158508158508\n",
      "epoch 362 validation acc: 0.5740741\n",
      "Train Epoch: 363 [0%]\tLoss: 0.208863\n",
      "Train Epoch: 363 [93%]\tLoss: 0.767311\n",
      "epoch 363 training loss: 0.29754249133919886 acc: 0.8694638694638694\n",
      "epoch 363 validation acc: 0.5648148\n",
      "Train Epoch: 364 [0%]\tLoss: 0.332984\n",
      "Train Epoch: 364 [93%]\tLoss: 0.042327\n",
      "epoch 364 training loss: 0.2805086824669987 acc: 0.8904428904428905\n",
      "epoch 364 validation acc: 0.6759259\n",
      "Train Epoch: 365 [0%]\tLoss: 0.125301\n",
      "Train Epoch: 365 [93%]\tLoss: 0.212950\n",
      "epoch 365 training loss: 0.29677065598123054 acc: 0.8601398601398601\n",
      "epoch 365 validation acc: 0.4351852\n",
      "Train Epoch: 366 [0%]\tLoss: 0.126355\n",
      "Train Epoch: 366 [93%]\tLoss: 0.148603\n",
      "epoch 366 training loss: 0.3023069426417351 acc: 0.8694638694638694\n",
      "epoch 366 validation acc: 0.5462963\n",
      "Train Epoch: 367 [0%]\tLoss: 0.739095\n",
      "Train Epoch: 367 [93%]\tLoss: 0.084313\n",
      "epoch 367 training loss: 0.298946998677113 acc: 0.8787878787878788\n",
      "epoch 367 validation acc: 0.5462963\n",
      "Train Epoch: 368 [0%]\tLoss: 0.990327\n",
      "Train Epoch: 368 [93%]\tLoss: 0.172941\n",
      "epoch 368 training loss: 0.2917106596847858 acc: 0.8624708624708625\n",
      "epoch 368 validation acc: 0.5\n",
      "Train Epoch: 369 [0%]\tLoss: 0.565394\n",
      "Train Epoch: 369 [93%]\tLoss: 0.494479\n",
      "epoch 369 training loss: 0.31917045456874704 acc: 0.8741258741258742\n",
      "epoch 369 validation acc: 0.6296296\n",
      "Train Epoch: 370 [0%]\tLoss: 0.154509\n",
      "Train Epoch: 370 [93%]\tLoss: 0.338220\n",
      "epoch 370 training loss: 0.30861005406930214 acc: 0.8601398601398601\n",
      "epoch 370 validation acc: 0.4537037\n",
      "Train Epoch: 371 [0%]\tLoss: 0.145634\n",
      "Train Epoch: 371 [93%]\tLoss: 0.215437\n",
      "epoch 371 training loss: 0.30487848683777785 acc: 0.8787878787878788\n",
      "epoch 371 validation acc: 0.6111111\n",
      "Train Epoch: 372 [0%]\tLoss: 0.123910\n",
      "Train Epoch: 372 [93%]\tLoss: 0.367212\n",
      "epoch 372 training loss: 0.29382113501843476 acc: 0.8811188811188811\n",
      "epoch 372 validation acc: 0.5833333\n",
      "Train Epoch: 373 [0%]\tLoss: 0.316607\n",
      "Train Epoch: 373 [93%]\tLoss: 0.100148\n",
      "epoch 373 training loss: 0.26723609004504933 acc: 0.8951048951048951\n",
      "epoch 373 validation acc: 0.6296296\n",
      "Train Epoch: 374 [0%]\tLoss: 0.473238\n",
      "Train Epoch: 374 [93%]\tLoss: 0.001811\n",
      "epoch 374 training loss: 0.29366949259700187 acc: 0.8671328671328671\n",
      "epoch 374 validation acc: 0.6018519\n",
      "Train Epoch: 375 [0%]\tLoss: 0.681595\n",
      "Train Epoch: 375 [93%]\tLoss: 0.056956\n",
      "epoch 375 training loss: 0.2956132402964781 acc: 0.8764568764568764\n",
      "epoch 375 validation acc: 0.5462963\n",
      "Train Epoch: 376 [0%]\tLoss: 0.661285\n",
      "Train Epoch: 376 [93%]\tLoss: 0.403691\n",
      "epoch 376 training loss: 0.3258823387937068 acc: 0.8508158508158508\n",
      "epoch 376 validation acc: 0.6481481\n",
      "Train Epoch: 377 [0%]\tLoss: 0.046110\n",
      "Train Epoch: 377 [93%]\tLoss: 0.406886\n",
      "epoch 377 training loss: 0.2603947957956094 acc: 0.8904428904428905\n",
      "epoch 377 validation acc: 0.5092593\n",
      "Train Epoch: 378 [0%]\tLoss: 0.548245\n",
      "Train Epoch: 378 [93%]\tLoss: 0.156486\n",
      "epoch 378 training loss: 0.25153734511264636 acc: 0.8997668997668997\n",
      "epoch 378 validation acc: 0.7037037\n",
      "Train Epoch: 379 [0%]\tLoss: 0.566979\n",
      "Train Epoch: 379 [93%]\tLoss: 0.253393\n",
      "epoch 379 training loss: 0.31106820699965787 acc: 0.8554778554778555\n",
      "epoch 379 validation acc: 0.6759259\n",
      "Train Epoch: 380 [0%]\tLoss: 0.167521\n",
      "Train Epoch: 380 [93%]\tLoss: 0.613487\n",
      "epoch 380 training loss: 0.3156078422465793 acc: 0.8578088578088578\n",
      "epoch 380 validation acc: 0.5555556\n",
      "Train Epoch: 381 [0%]\tLoss: 0.200947\n",
      "Train Epoch: 381 [93%]\tLoss: 0.449563\n",
      "epoch 381 training loss: 0.28237799171054373 acc: 0.8764568764568764\n",
      "epoch 381 validation acc: 0.6111111\n",
      "Train Epoch: 382 [0%]\tLoss: 0.258037\n",
      "Train Epoch: 382 [93%]\tLoss: 0.793361\n",
      "epoch 382 training loss: 0.3249772904113073 acc: 0.8624708624708625\n",
      "epoch 382 validation acc: 0.5648148\n",
      "Train Epoch: 383 [0%]\tLoss: 0.030995\n",
      "Train Epoch: 383 [93%]\tLoss: 0.101323\n",
      "epoch 383 training loss: 0.3353025217883341 acc: 0.8531468531468531\n",
      "epoch 383 validation acc: 0.6296296\n",
      "Train Epoch: 384 [0%]\tLoss: 0.610269\n",
      "Train Epoch: 384 [93%]\tLoss: 0.400295\n",
      "epoch 384 training loss: 0.2796426730519333 acc: 0.8974358974358975\n",
      "epoch 384 validation acc: 0.6296296\n",
      "Train Epoch: 385 [0%]\tLoss: 0.152951\n",
      "Train Epoch: 385 [93%]\tLoss: 0.055443\n",
      "epoch 385 training loss: 0.2891951498663898 acc: 0.8741258741258742\n",
      "epoch 385 validation acc: 0.6851852\n",
      "Train Epoch: 386 [0%]\tLoss: 0.167913\n",
      "Train Epoch: 386 [93%]\tLoss: 0.229860\n",
      "epoch 386 training loss: 0.26405645988954884 acc: 0.8787878787878788\n",
      "epoch 386 validation acc: 0.6481481\n",
      "Train Epoch: 387 [0%]\tLoss: 0.161516\n",
      "Train Epoch: 387 [93%]\tLoss: 0.022712\n",
      "epoch 387 training loss: 0.24894251047226135 acc: 0.8694638694638694\n",
      "epoch 387 validation acc: 0.5648148\n",
      "Train Epoch: 388 [0%]\tLoss: 0.576215\n",
      "Train Epoch: 388 [93%]\tLoss: 0.120654\n",
      "epoch 388 training loss: 0.23269538822717517 acc: 0.8927738927738927\n",
      "epoch 388 validation acc: 0.6481481\n",
      "Train Epoch: 389 [0%]\tLoss: 0.518862\n",
      "Train Epoch: 389 [93%]\tLoss: 0.238533\n",
      "epoch 389 training loss: 0.29448949460250634 acc: 0.8694638694638694\n",
      "epoch 389 validation acc: 0.5277778\n",
      "Train Epoch: 390 [0%]\tLoss: 0.116773\n",
      "Train Epoch: 390 [93%]\tLoss: 0.422418\n",
      "epoch 390 training loss: 0.29278260677151763 acc: 0.8624708624708625\n",
      "epoch 390 validation acc: 0.7037037\n",
      "Train Epoch: 391 [0%]\tLoss: 0.046468\n",
      "Train Epoch: 391 [93%]\tLoss: 0.335986\n",
      "epoch 391 training loss: 0.2897535881068136 acc: 0.8554778554778555\n",
      "epoch 391 validation acc: 0.6203704\n",
      "Train Epoch: 392 [0%]\tLoss: 0.066980\n",
      "Train Epoch: 392 [93%]\tLoss: 1.457772\n",
      "epoch 392 training loss: 0.2878447504826235 acc: 0.8671328671328671\n",
      "epoch 392 validation acc: 0.6388889\n",
      "Train Epoch: 393 [0%]\tLoss: 0.055361\n",
      "Train Epoch: 393 [93%]\tLoss: 0.223593\n",
      "epoch 393 training loss: 0.24931155865865381 acc: 0.9090909090909091\n",
      "epoch 393 validation acc: 0.7037037\n",
      "Train Epoch: 394 [0%]\tLoss: 0.071144\n",
      "Train Epoch: 394 [93%]\tLoss: 0.066227\n",
      "epoch 394 training loss: 0.28269559957287266 acc: 0.8741258741258742\n",
      "epoch 394 validation acc: 0.6296296\n",
      "Train Epoch: 395 [0%]\tLoss: 0.047196\n",
      "Train Epoch: 395 [93%]\tLoss: 0.067564\n",
      "epoch 395 training loss: 0.26583141336407234 acc: 0.8764568764568764\n",
      "epoch 395 validation acc: 0.6851852\n",
      "Train Epoch: 396 [0%]\tLoss: 0.033779\n",
      "Train Epoch: 396 [93%]\tLoss: 1.066410\n",
      "epoch 396 training loss: 0.3217636353715702 acc: 0.8694638694638694\n",
      "epoch 396 validation acc: 0.5555556\n",
      "Train Epoch: 397 [0%]\tLoss: 0.268016\n",
      "Train Epoch: 397 [93%]\tLoss: 0.152469\n",
      "epoch 397 training loss: 0.2728674687376177 acc: 0.8764568764568764\n",
      "epoch 397 validation acc: 0.6481481\n",
      "Train Epoch: 398 [0%]\tLoss: 0.017422\n",
      "Train Epoch: 398 [93%]\tLoss: 0.659281\n",
      "epoch 398 training loss: 0.2880630758731126 acc: 0.8671328671328671\n",
      "epoch 398 validation acc: 0.6666667\n",
      "Train Epoch: 399 [0%]\tLoss: 0.085368\n",
      "Train Epoch: 399 [93%]\tLoss: 0.291341\n",
      "epoch 399 training loss: 0.30610791405369703 acc: 0.8787878787878788\n",
      "epoch 399 validation acc: 0.6111111\n",
      "Train Epoch: 400 [0%]\tLoss: 0.186802\n",
      "Train Epoch: 400 [93%]\tLoss: 0.334862\n",
      "epoch 400 training loss: 0.2847948547547545 acc: 0.8811188811188811\n",
      "epoch 400 validation acc: 0.537037\n",
      "Train Epoch: 401 [0%]\tLoss: 0.320430\n",
      "Train Epoch: 401 [93%]\tLoss: 0.238172\n",
      "epoch 401 training loss: 0.28815330221119373 acc: 0.8648018648018648\n",
      "epoch 401 validation acc: 0.6111111\n",
      "Train Epoch: 402 [0%]\tLoss: 0.662723\n",
      "Train Epoch: 402 [93%]\tLoss: 0.382421\n",
      "epoch 402 training loss: 0.29264746338486913 acc: 0.8857808857808858\n",
      "epoch 402 validation acc: 0.5462963\n",
      "Train Epoch: 403 [0%]\tLoss: 0.641593\n",
      "Train Epoch: 403 [93%]\tLoss: 0.254197\n",
      "epoch 403 training loss: 0.27879720359730226 acc: 0.8741258741258742\n",
      "epoch 403 validation acc: 0.6666667\n",
      "Train Epoch: 404 [0%]\tLoss: 0.009626\n",
      "Train Epoch: 404 [93%]\tLoss: 0.054129\n",
      "epoch 404 training loss: 0.2659831395700436 acc: 0.8904428904428905\n",
      "epoch 404 validation acc: 0.6018519\n",
      "Train Epoch: 405 [0%]\tLoss: 0.124356\n",
      "Train Epoch: 405 [93%]\tLoss: 0.671624\n",
      "epoch 405 training loss: 0.26614084566891605 acc: 0.8764568764568764\n",
      "epoch 405 validation acc: 0.6388889\n",
      "Train Epoch: 406 [0%]\tLoss: 0.286278\n",
      "Train Epoch: 406 [93%]\tLoss: 0.255188\n",
      "epoch 406 training loss: 0.2705601459041376 acc: 0.8811188811188811\n",
      "epoch 406 validation acc: 0.6111111\n",
      "Train Epoch: 407 [0%]\tLoss: 0.450329\n",
      "Train Epoch: 407 [93%]\tLoss: 0.395358\n",
      "epoch 407 training loss: 0.2955697091917197 acc: 0.8531468531468531\n",
      "epoch 407 validation acc: 0.6111111\n",
      "Train Epoch: 408 [0%]\tLoss: 0.034269\n",
      "Train Epoch: 408 [93%]\tLoss: 0.052106\n",
      "epoch 408 training loss: 0.2624115994139747 acc: 0.8648018648018648\n",
      "epoch 408 validation acc: 0.6944444\n",
      "Train Epoch: 409 [0%]\tLoss: 0.310805\n",
      "Train Epoch: 409 [93%]\tLoss: 0.025087\n",
      "epoch 409 training loss: 0.27426481727269236 acc: 0.8741258741258742\n",
      "epoch 409 validation acc: 0.5740741\n",
      "Train Epoch: 410 [0%]\tLoss: 0.160332\n",
      "Train Epoch: 410 [93%]\tLoss: 0.233296\n",
      "epoch 410 training loss: 0.2740784951009253 acc: 0.8741258741258742\n",
      "epoch 410 validation acc: 0.6296296\n",
      "Train Epoch: 411 [0%]\tLoss: 0.220738\n",
      "Train Epoch: 411 [93%]\tLoss: 0.076791\n",
      "epoch 411 training loss: 0.2997588656273567 acc: 0.8648018648018648\n",
      "epoch 411 validation acc: 0.5925926\n",
      "Train Epoch: 412 [0%]\tLoss: 0.078491\n",
      "Train Epoch: 412 [93%]\tLoss: 0.275357\n",
      "epoch 412 training loss: 0.3045113039660026 acc: 0.8624708624708625\n",
      "epoch 412 validation acc: 0.6481481\n",
      "Train Epoch: 413 [0%]\tLoss: 0.384564\n",
      "Train Epoch: 413 [93%]\tLoss: 0.017829\n",
      "epoch 413 training loss: 0.24245049077068903 acc: 0.8951048951048951\n",
      "epoch 413 validation acc: 0.6111111\n",
      "Train Epoch: 414 [0%]\tLoss: 0.044237\n",
      "Train Epoch: 414 [93%]\tLoss: 0.022364\n",
      "epoch 414 training loss: 0.27580683728404065 acc: 0.8764568764568764\n",
      "epoch 414 validation acc: 0.6481481\n",
      "Train Epoch: 415 [0%]\tLoss: 0.040501\n",
      "Train Epoch: 415 [93%]\tLoss: 0.176715\n",
      "epoch 415 training loss: 0.2650636908839698 acc: 0.8881118881118881\n",
      "epoch 415 validation acc: 0.6944444\n",
      "Train Epoch: 416 [0%]\tLoss: 0.413974\n",
      "Train Epoch: 416 [93%]\tLoss: 0.034149\n",
      "epoch 416 training loss: 0.29739916680975714 acc: 0.8741258741258742\n",
      "epoch 416 validation acc: 0.5555556\n",
      "Train Epoch: 417 [0%]\tLoss: 0.220448\n",
      "Train Epoch: 417 [93%]\tLoss: 0.341115\n",
      "epoch 417 training loss: 0.2952017216701719 acc: 0.8671328671328671\n",
      "epoch 417 validation acc: 0.6111111\n",
      "Train Epoch: 418 [0%]\tLoss: 0.085567\n",
      "Train Epoch: 418 [93%]\tLoss: 0.163481\n",
      "epoch 418 training loss: 0.29370965157135354 acc: 0.8717948717948718\n",
      "epoch 418 validation acc: 0.5\n",
      "Train Epoch: 419 [0%]\tLoss: 0.116379\n",
      "Train Epoch: 419 [93%]\tLoss: 0.632744\n",
      "epoch 419 training loss: 0.27759740584581405 acc: 0.8787878787878788\n",
      "epoch 419 validation acc: 0.6203704\n",
      "Train Epoch: 420 [0%]\tLoss: 0.305620\n",
      "Train Epoch: 420 [93%]\tLoss: 0.065680\n",
      "epoch 420 training loss: 0.2722328133467171 acc: 0.8811188811188811\n",
      "epoch 420 validation acc: 0.6388889\n",
      "Train Epoch: 421 [0%]\tLoss: 0.661643\n",
      "Train Epoch: 421 [93%]\tLoss: 0.031660\n",
      "epoch 421 training loss: 0.25770002140456605 acc: 0.8834498834498834\n",
      "epoch 421 validation acc: 0.6481481\n",
      "Train Epoch: 422 [0%]\tLoss: 0.242098\n",
      "Train Epoch: 422 [93%]\tLoss: 0.076574\n",
      "epoch 422 training loss: 0.26805996972446217 acc: 0.8834498834498834\n",
      "epoch 422 validation acc: 0.6296296\n",
      "Train Epoch: 423 [0%]\tLoss: 0.604880\n",
      "Train Epoch: 423 [93%]\tLoss: 0.100421\n",
      "epoch 423 training loss: 0.2872744027387213 acc: 0.8717948717948718\n",
      "epoch 423 validation acc: 0.5277778\n",
      "Train Epoch: 424 [0%]\tLoss: 0.175721\n",
      "Train Epoch: 424 [93%]\tLoss: 0.086251\n",
      "epoch 424 training loss: 0.2989340258279332 acc: 0.8787878787878788\n",
      "epoch 424 validation acc: 0.5833333\n",
      "Train Epoch: 425 [0%]\tLoss: 0.523380\n",
      "Train Epoch: 425 [93%]\tLoss: 0.246784\n",
      "epoch 425 training loss: 0.31496299784204757 acc: 0.8578088578088578\n",
      "epoch 425 validation acc: 0.6851852\n",
      "Train Epoch: 426 [0%]\tLoss: 0.431744\n",
      "Train Epoch: 426 [93%]\tLoss: 0.705438\n",
      "epoch 426 training loss: 0.27649059380335667 acc: 0.8787878787878788\n",
      "epoch 426 validation acc: 0.6296296\n",
      "Train Epoch: 427 [0%]\tLoss: 0.064832\n",
      "Train Epoch: 427 [93%]\tLoss: 0.059504\n",
      "epoch 427 training loss: 0.26451129986068095 acc: 0.8834498834498834\n",
      "epoch 427 validation acc: 0.6388889\n",
      "Train Epoch: 428 [0%]\tLoss: 0.077347\n",
      "Train Epoch: 428 [93%]\tLoss: 0.215133\n",
      "epoch 428 training loss: 0.29364517618281144 acc: 0.8904428904428905\n",
      "epoch 428 validation acc: 0.6296296\n",
      "Train Epoch: 429 [0%]\tLoss: 0.184993\n",
      "Train Epoch: 429 [93%]\tLoss: 0.284285\n",
      "epoch 429 training loss: 0.25357784579359255 acc: 0.8997668997668997\n",
      "epoch 429 validation acc: 0.6388889\n",
      "Train Epoch: 430 [0%]\tLoss: 0.375196\n",
      "Train Epoch: 430 [93%]\tLoss: 0.181928\n",
      "epoch 430 training loss: 0.2841763477341075 acc: 0.8857808857808858\n",
      "epoch 430 validation acc: 0.6851852\n",
      "Train Epoch: 431 [0%]\tLoss: 0.043643\n",
      "Train Epoch: 431 [93%]\tLoss: 0.084726\n",
      "epoch 431 training loss: 0.26791829599015826 acc: 0.8694638694638694\n",
      "epoch 431 validation acc: 0.6296296\n",
      "Train Epoch: 432 [0%]\tLoss: 0.545786\n",
      "Train Epoch: 432 [93%]\tLoss: 0.318522\n",
      "epoch 432 training loss: 0.25534172099152647 acc: 0.8811188811188811\n",
      "epoch 432 validation acc: 0.5092593\n",
      "Train Epoch: 433 [0%]\tLoss: 0.085369\n",
      "Train Epoch: 433 [93%]\tLoss: 1.372660\n",
      "epoch 433 training loss: 0.23711637585829184 acc: 0.8927738927738927\n",
      "epoch 433 validation acc: 0.7314815\n",
      "Train Epoch: 434 [0%]\tLoss: 0.031919\n",
      "Train Epoch: 434 [93%]\tLoss: 0.124198\n",
      "epoch 434 training loss: 0.3369739796940444 acc: 0.8601398601398601\n",
      "epoch 434 validation acc: 0.6666667\n",
      "Train Epoch: 435 [0%]\tLoss: 0.225705\n",
      "Train Epoch: 435 [93%]\tLoss: 0.072943\n",
      "epoch 435 training loss: 0.29360633360273725 acc: 0.8671328671328671\n",
      "epoch 435 validation acc: 0.5925926\n",
      "Train Epoch: 436 [0%]\tLoss: 0.003561\n",
      "Train Epoch: 436 [93%]\tLoss: 0.089245\n",
      "epoch 436 training loss: 0.2796689572644903 acc: 0.8974358974358975\n",
      "epoch 436 validation acc: 0.6481481\n",
      "Train Epoch: 437 [0%]\tLoss: 1.077056\n",
      "Train Epoch: 437 [93%]\tLoss: 0.190555\n",
      "epoch 437 training loss: 0.2455817239134814 acc: 0.8881118881118881\n",
      "epoch 437 validation acc: 0.6574074\n",
      "Train Epoch: 438 [0%]\tLoss: 0.250041\n",
      "Train Epoch: 438 [93%]\tLoss: 0.045533\n",
      "epoch 438 training loss: 0.25353130199342827 acc: 0.8881118881118881\n",
      "epoch 438 validation acc: 0.6481481\n",
      "Train Epoch: 439 [0%]\tLoss: 0.119315\n",
      "Train Epoch: 439 [93%]\tLoss: 0.365882\n",
      "epoch 439 training loss: 0.2653311938047409 acc: 0.8974358974358975\n",
      "epoch 439 validation acc: 0.6481481\n",
      "Train Epoch: 440 [0%]\tLoss: 0.286857\n",
      "Train Epoch: 440 [93%]\tLoss: 0.062114\n",
      "epoch 440 training loss: 0.2611086482044119 acc: 0.8881118881118881\n",
      "epoch 440 validation acc: 0.6111111\n",
      "Train Epoch: 441 [0%]\tLoss: 0.029550\n",
      "Train Epoch: 441 [93%]\tLoss: 0.061355\n",
      "epoch 441 training loss: 0.25822468842293517 acc: 0.8741258741258742\n",
      "epoch 441 validation acc: 0.6481481\n",
      "Train Epoch: 442 [0%]\tLoss: 0.612809\n",
      "Train Epoch: 442 [93%]\tLoss: 0.135681\n",
      "epoch 442 training loss: 0.2629826138753136 acc: 0.8787878787878788\n",
      "epoch 442 validation acc: 0.6759259\n",
      "Train Epoch: 443 [0%]\tLoss: 0.043367\n",
      "Train Epoch: 443 [93%]\tLoss: 0.448395\n",
      "epoch 443 training loss: 0.26794261756973964 acc: 0.8787878787878788\n",
      "epoch 443 validation acc: 0.712963\n",
      "Train Epoch: 444 [0%]\tLoss: 0.061790\n",
      "Train Epoch: 444 [93%]\tLoss: 0.136969\n",
      "epoch 444 training loss: 0.2690736550209328 acc: 0.8881118881118881\n",
      "epoch 444 validation acc: 0.4537037\n",
      "Train Epoch: 445 [0%]\tLoss: 0.095420\n",
      "Train Epoch: 445 [93%]\tLoss: 0.255538\n",
      "epoch 445 training loss: 0.25740118068642914 acc: 0.8881118881118881\n",
      "epoch 445 validation acc: 0.6018519\n",
      "Train Epoch: 446 [0%]\tLoss: 0.467120\n",
      "Train Epoch: 446 [93%]\tLoss: 0.015446\n",
      "epoch 446 training loss: 0.2759423210647785 acc: 0.8764568764568764\n",
      "epoch 446 validation acc: 0.6111111\n",
      "Train Epoch: 447 [0%]\tLoss: 0.047522\n",
      "Train Epoch: 447 [93%]\tLoss: 0.050700\n",
      "epoch 447 training loss: 0.2904043282270087 acc: 0.8741258741258742\n",
      "epoch 447 validation acc: 0.6111111\n",
      "Train Epoch: 448 [0%]\tLoss: 0.068316\n",
      "Train Epoch: 448 [93%]\tLoss: 0.401213\n",
      "epoch 448 training loss: 0.2757068854855418 acc: 0.8741258741258742\n",
      "epoch 448 validation acc: 0.5925926\n",
      "Train Epoch: 449 [0%]\tLoss: 0.667854\n",
      "Train Epoch: 449 [93%]\tLoss: 0.293375\n",
      "epoch 449 training loss: 0.23870689988581473 acc: 0.8904428904428905\n",
      "epoch 449 validation acc: 0.6296296\n",
      "Train Epoch: 450 [0%]\tLoss: 0.010056\n",
      "Train Epoch: 450 [93%]\tLoss: 0.555390\n",
      "epoch 450 training loss: 0.2620492399736939 acc: 0.8834498834498834\n",
      "epoch 450 validation acc: 0.6944444\n",
      "Train Epoch: 451 [0%]\tLoss: 0.077030\n",
      "Train Epoch: 451 [93%]\tLoss: 0.411421\n",
      "epoch 451 training loss: 0.256102611164183 acc: 0.8974358974358975\n",
      "epoch 451 validation acc: 0.6111111\n",
      "Train Epoch: 452 [0%]\tLoss: 0.175127\n",
      "Train Epoch: 452 [93%]\tLoss: 0.129935\n",
      "epoch 452 training loss: 0.27430433816388594 acc: 0.8787878787878788\n",
      "epoch 452 validation acc: 0.4722222\n",
      "Train Epoch: 453 [0%]\tLoss: 0.727203\n",
      "Train Epoch: 453 [93%]\tLoss: 0.058000\n",
      "epoch 453 training loss: 0.2794607803729445 acc: 0.8624708624708625\n",
      "epoch 453 validation acc: 0.6759259\n",
      "Train Epoch: 454 [0%]\tLoss: 0.127988\n",
      "Train Epoch: 454 [93%]\tLoss: 0.040128\n",
      "epoch 454 training loss: 0.24576364852988195 acc: 0.8974358974358975\n",
      "epoch 454 validation acc: 0.6944444\n",
      "Train Epoch: 455 [0%]\tLoss: 0.019909\n",
      "Train Epoch: 455 [93%]\tLoss: 0.161225\n",
      "epoch 455 training loss: 0.26240425988497146 acc: 0.8811188811188811\n",
      "epoch 455 validation acc: 0.7037037\n",
      "Train Epoch: 456 [0%]\tLoss: 0.074417\n",
      "Train Epoch: 456 [93%]\tLoss: 0.248976\n",
      "epoch 456 training loss: 0.24073325196298323 acc: 0.9067599067599068\n",
      "epoch 456 validation acc: 0.7314815\n",
      "Train Epoch: 457 [0%]\tLoss: 0.515924\n",
      "Train Epoch: 457 [93%]\tLoss: 0.709800\n",
      "epoch 457 training loss: 0.30976706819557065 acc: 0.8508158508158508\n",
      "epoch 457 validation acc: 0.5925926\n",
      "Train Epoch: 458 [0%]\tLoss: 0.042650\n",
      "Train Epoch: 458 [93%]\tLoss: 0.209563\n",
      "epoch 458 training loss: 0.2403294505945976 acc: 0.8974358974358975\n",
      "epoch 458 validation acc: 0.7222222\n",
      "Train Epoch: 459 [0%]\tLoss: 0.325036\n",
      "Train Epoch: 459 [93%]\tLoss: 0.396150\n",
      "epoch 459 training loss: 0.28130074584408216 acc: 0.8787878787878788\n",
      "epoch 459 validation acc: 0.5185185\n",
      "Train Epoch: 460 [0%]\tLoss: 0.101877\n",
      "Train Epoch: 460 [93%]\tLoss: 0.221071\n",
      "epoch 460 training loss: 0.3056154362684875 acc: 0.8741258741258742\n",
      "epoch 460 validation acc: 0.6018519\n",
      "Train Epoch: 461 [0%]\tLoss: 0.104067\n",
      "Train Epoch: 461 [93%]\tLoss: 0.151713\n",
      "epoch 461 training loss: 0.3116570894597788 acc: 0.8624708624708625\n",
      "epoch 461 validation acc: 0.49074075\n",
      "Train Epoch: 462 [0%]\tLoss: 0.087604\n",
      "Train Epoch: 462 [93%]\tLoss: 0.337981\n",
      "epoch 462 training loss: 0.30736665475975583 acc: 0.8554778554778555\n",
      "epoch 462 validation acc: 0.6388889\n",
      "Train Epoch: 463 [0%]\tLoss: 0.174782\n",
      "Train Epoch: 463 [93%]\tLoss: 0.265813\n",
      "epoch 463 training loss: 0.2603010276733484 acc: 0.8857808857808858\n",
      "epoch 463 validation acc: 0.6111111\n",
      "Train Epoch: 464 [0%]\tLoss: 0.219253\n",
      "Train Epoch: 464 [93%]\tLoss: 0.274744\n",
      "epoch 464 training loss: 0.2889990608414842 acc: 0.8694638694638694\n",
      "epoch 464 validation acc: 0.6111111\n",
      "Train Epoch: 465 [0%]\tLoss: 0.007278\n",
      "Train Epoch: 465 [93%]\tLoss: 0.400065\n",
      "epoch 465 training loss: 0.28067206747881657 acc: 0.8717948717948718\n",
      "epoch 465 validation acc: 0.6759259\n",
      "Train Epoch: 466 [0%]\tLoss: 0.158398\n",
      "Train Epoch: 466 [93%]\tLoss: 0.463201\n",
      "epoch 466 training loss: 0.2858703811205285 acc: 0.8787878787878788\n",
      "epoch 466 validation acc: 0.6574074\n",
      "Train Epoch: 467 [0%]\tLoss: 0.154031\n",
      "Train Epoch: 467 [93%]\tLoss: 0.188698\n",
      "epoch 467 training loss: 0.274808753680662 acc: 0.8881118881118881\n",
      "epoch 467 validation acc: 0.5185185\n",
      "Train Epoch: 468 [0%]\tLoss: 0.189671\n",
      "Train Epoch: 468 [93%]\tLoss: 0.105753\n",
      "epoch 468 training loss: 0.28427912109031306 acc: 0.8811188811188811\n",
      "epoch 468 validation acc: 0.6481481\n",
      "Train Epoch: 469 [0%]\tLoss: 0.104511\n",
      "Train Epoch: 469 [93%]\tLoss: 0.386041\n",
      "epoch 469 training loss: 0.29413221778722126 acc: 0.8717948717948718\n",
      "epoch 469 validation acc: 0.6018519\n",
      "Train Epoch: 470 [0%]\tLoss: 0.401733\n",
      "Train Epoch: 470 [93%]\tLoss: 0.143357\n",
      "epoch 470 training loss: 0.2798568106374188 acc: 0.8624708624708625\n",
      "epoch 470 validation acc: 0.4814815\n",
      "Train Epoch: 471 [0%]\tLoss: 0.114905\n",
      "Train Epoch: 471 [93%]\tLoss: 0.177865\n",
      "epoch 471 training loss: 0.28401896463388027 acc: 0.8741258741258742\n",
      "epoch 471 validation acc: 0.6666667\n",
      "Train Epoch: 472 [0%]\tLoss: 0.156239\n",
      "Train Epoch: 472 [93%]\tLoss: 0.205484\n",
      "epoch 472 training loss: 0.2718897301669198 acc: 0.8834498834498834\n",
      "epoch 472 validation acc: 0.3888889\n",
      "Train Epoch: 473 [0%]\tLoss: 0.004649\n",
      "Train Epoch: 473 [93%]\tLoss: 0.049152\n",
      "epoch 473 training loss: 0.2922818409759674 acc: 0.8624708624708625\n",
      "epoch 473 validation acc: 0.7685185\n",
      "Train Epoch: 474 [0%]\tLoss: 0.848542\n",
      "Train Epoch: 474 [93%]\tLoss: 0.057726\n",
      "epoch 474 training loss: 0.2913817913913927 acc: 0.8857808857808858\n",
      "epoch 474 validation acc: 0.6296296\n",
      "Train Epoch: 475 [0%]\tLoss: 0.384369\n",
      "Train Epoch: 475 [93%]\tLoss: 0.226912\n",
      "epoch 475 training loss: 0.3060568281449647 acc: 0.8717948717948718\n",
      "epoch 475 validation acc: 0.6296296\n",
      "Train Epoch: 476 [0%]\tLoss: 0.273725\n",
      "Train Epoch: 476 [93%]\tLoss: 0.378392\n",
      "epoch 476 training loss: 0.28393211000150553 acc: 0.8717948717948718\n",
      "epoch 476 validation acc: 0.6759259\n",
      "Train Epoch: 477 [0%]\tLoss: 0.033192\n",
      "Train Epoch: 477 [93%]\tLoss: 0.060084\n",
      "epoch 477 training loss: 0.29925396138181287 acc: 0.8741258741258742\n",
      "epoch 477 validation acc: 0.5\n",
      "Train Epoch: 478 [0%]\tLoss: 0.347106\n",
      "Train Epoch: 478 [93%]\tLoss: 0.043855\n",
      "epoch 478 training loss: 0.25199135711106163 acc: 0.9020979020979021\n",
      "epoch 478 validation acc: 0.6759259\n",
      "Train Epoch: 479 [0%]\tLoss: 0.158061\n",
      "Train Epoch: 479 [93%]\tLoss: 0.910893\n",
      "epoch 479 training loss: 0.28266706296967137 acc: 0.8648018648018648\n",
      "epoch 479 validation acc: 0.5648148\n",
      "Train Epoch: 480 [0%]\tLoss: 0.040905\n",
      "Train Epoch: 480 [93%]\tLoss: 0.432265\n",
      "epoch 480 training loss: 0.280479873593625 acc: 0.8764568764568764\n",
      "epoch 480 validation acc: 0.4814815\n",
      "Train Epoch: 481 [0%]\tLoss: 0.111903\n",
      "Train Epoch: 481 [93%]\tLoss: 0.779312\n",
      "epoch 481 training loss: 0.26843924201616404 acc: 0.8717948717948718\n",
      "epoch 481 validation acc: 0.5925926\n",
      "Train Epoch: 482 [0%]\tLoss: 0.081304\n",
      "Train Epoch: 482 [93%]\tLoss: 0.075694\n",
      "epoch 482 training loss: 0.2728794639395481 acc: 0.8904428904428905\n",
      "epoch 482 validation acc: 0.44444445\n",
      "Train Epoch: 483 [0%]\tLoss: 0.638592\n",
      "Train Epoch: 483 [93%]\tLoss: 0.057722\n",
      "epoch 483 training loss: 0.2612930599782515 acc: 0.8974358974358975\n",
      "epoch 483 validation acc: 0.5555556\n",
      "Train Epoch: 484 [0%]\tLoss: 0.436852\n",
      "Train Epoch: 484 [93%]\tLoss: 0.005946\n",
      "epoch 484 training loss: 0.31227722531359714 acc: 0.8741258741258742\n",
      "epoch 484 validation acc: 0.6018519\n",
      "Train Epoch: 485 [0%]\tLoss: 0.172611\n",
      "Train Epoch: 485 [93%]\tLoss: 0.059286\n",
      "epoch 485 training loss: 0.2506805720132198 acc: 0.8927738927738927\n",
      "epoch 485 validation acc: 0.6203704\n",
      "Train Epoch: 486 [0%]\tLoss: 0.053788\n",
      "Train Epoch: 486 [93%]\tLoss: 0.051945\n",
      "epoch 486 training loss: 0.2850191659397549 acc: 0.8671328671328671\n",
      "epoch 486 validation acc: 0.5833333\n",
      "Train Epoch: 487 [0%]\tLoss: 0.201685\n",
      "Train Epoch: 487 [93%]\tLoss: 0.186234\n",
      "epoch 487 training loss: 0.30588690341553754 acc: 0.8764568764568764\n",
      "epoch 487 validation acc: 0.5648148\n",
      "Train Epoch: 488 [0%]\tLoss: 0.680385\n",
      "Train Epoch: 488 [93%]\tLoss: 1.206319\n",
      "epoch 488 training loss: 0.3198860579653195 acc: 0.8811188811188811\n",
      "epoch 488 validation acc: 0.4074074\n",
      "Train Epoch: 489 [0%]\tLoss: 0.365852\n",
      "Train Epoch: 489 [93%]\tLoss: 0.128047\n",
      "epoch 489 training loss: 0.258318747902565 acc: 0.8881118881118881\n",
      "epoch 489 validation acc: 0.537037\n",
      "Train Epoch: 490 [0%]\tLoss: 0.024322\n",
      "Train Epoch: 490 [93%]\tLoss: 0.653450\n",
      "epoch 490 training loss: 0.2724459148561841 acc: 0.8904428904428905\n",
      "epoch 490 validation acc: 0.6388889\n",
      "Train Epoch: 491 [0%]\tLoss: 0.018049\n",
      "Train Epoch: 491 [93%]\tLoss: 0.087759\n",
      "epoch 491 training loss: 0.2708813223461793 acc: 0.8787878787878788\n",
      "epoch 491 validation acc: 0.4722222\n",
      "Train Epoch: 492 [0%]\tLoss: 0.149344\n",
      "Train Epoch: 492 [93%]\tLoss: 0.246640\n",
      "epoch 492 training loss: 0.2745970192330855 acc: 0.8764568764568764\n",
      "epoch 492 validation acc: 0.6388889\n",
      "Train Epoch: 493 [0%]\tLoss: 0.044622\n",
      "Train Epoch: 493 [93%]\tLoss: 0.155023\n",
      "epoch 493 training loss: 0.25910317314857684 acc: 0.8811188811188811\n",
      "epoch 493 validation acc: 0.6111111\n",
      "Train Epoch: 494 [0%]\tLoss: 0.036587\n",
      "Train Epoch: 494 [93%]\tLoss: 0.175672\n",
      "epoch 494 training loss: 0.2732016943584852 acc: 0.8717948717948718\n",
      "epoch 494 validation acc: 0.6666667\n",
      "Train Epoch: 495 [0%]\tLoss: 0.289402\n",
      "Train Epoch: 495 [93%]\tLoss: 0.119186\n",
      "epoch 495 training loss: 0.2777187922087655 acc: 0.8624708624708625\n",
      "epoch 495 validation acc: 0.6111111\n",
      "Train Epoch: 496 [0%]\tLoss: 0.106231\n",
      "Train Epoch: 496 [93%]\tLoss: 0.121695\n",
      "epoch 496 training loss: 0.28343021437305854 acc: 0.8717948717948718\n",
      "epoch 496 validation acc: 0.4722222\n",
      "Train Epoch: 497 [0%]\tLoss: 0.512635\n",
      "Train Epoch: 497 [93%]\tLoss: 0.581739\n",
      "epoch 497 training loss: 0.3040540062615441 acc: 0.8741258741258742\n",
      "epoch 497 validation acc: 0.6203704\n",
      "Train Epoch: 498 [0%]\tLoss: 0.135198\n",
      "Train Epoch: 498 [93%]\tLoss: 0.080557\n",
      "epoch 498 training loss: 0.27400078259287747 acc: 0.8904428904428905\n",
      "epoch 498 validation acc: 0.6296296\n",
      "Train Epoch: 499 [0%]\tLoss: 0.085186\n",
      "Train Epoch: 499 [93%]\tLoss: 0.096095\n",
      "epoch 499 training loss: 0.2617684649843189 acc: 0.8904428904428905\n",
      "epoch 499 validation acc: 0.6296296\n"
     ]
    }
   ],
   "source": [
    "best_acc_val = -9999\n",
    "for epoch in range(epoch_save+1, 500):\n",
    "    #-------- training --------------------------------\n",
    "    loss_train, acc_train =train(model, device, optimizer, loader_train, epoch)    \n",
    "    loss_train_list.append(loss_train)\n",
    "    acc_train_list.append(acc_train)\n",
    "    print('epoch', epoch, 'training loss:', loss_train, 'acc:', acc_train)\n",
    "    #-------- validation --------------------------------\n",
    "    acc_val, other_val, _, __ = test(model, device, loader_val)\n",
    "    acc_val_list.append(acc_val)\n",
    "    print('epoch', epoch, 'validation acc:', acc_val)\n",
    "    #--------save model-------------------------\n",
    "    result = (loss_train_list, acc_train_list, \n",
    "              acc_val_list, other_val)\n",
    "    if acc_val > best_acc_val:\n",
    "        best_acc_val = acc_val\n",
    "        torch.save(model.state_dict(), 'best_model_6.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6b816892-2f6f-4e4d-914a-4b4c1e06f508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7962963"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(acc_val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "38553921-948d-41c7-b672-92e6817cfc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_epoch=np.argmax(acc_val_list)\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "4307504b-63de-4f1e-b6ed-83ea7b1d3ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(1, 256, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "  (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (conv3): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (conv4): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "  (conv5): Conv1d(256, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (fc1): Linear(in_features=2, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avg1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "  (avg2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "  (avg3): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previous model was better\n",
    "model=Net()\n",
    "model.load_state_dict(torch.load('best_model_4.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c370367-65e7-4eb1-9128-bfdc62ae61f5",
   "metadata": {},
   "source": [
    "## validation set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "bdad4410-e961-4b9a-84b4-707570420548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (average) 0.8425926\n",
      "Recall [0.875      0.77777779]\n",
      "Precision [0.88732392 0.75675678]\n",
      "Confusion \n",
      " [[63.  9.]\n",
      " [ 8. 28.]]\n",
      "F1 Score: 0.7671232876712328\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAccuracy (average) 0.8425926\\nRecall [0.875      0.77777779]\\nPrecision [0.88732392 0.75675678]\\nConfusion \\n [[63.  9.]\\n [ 8. 28.]]\\nF1 Score: 0.7671232876712328\\n'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, (confusion, recall, prec), Ys, Yps = test(model, device, loader_val)\n",
    "print('Accuracy (average)', acc)\n",
    "print('Recall', recall)\n",
    "print('Precision', prec)\n",
    "print('Confusion \\n', confusion)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(Ys, Yps)\n",
    "\n",
    "print(\"F1 Score:\", f1)\n",
    "'''\n",
    "Accuracy (average) 0.8425926\n",
    "Recall [0.875      0.77777779]\n",
    "Precision [0.88732392 0.75675678]\n",
    "Confusion \n",
    " [[63.  9.]\n",
    " [ 8. 28.]]\n",
    "F1 Score: 0.7671232876712328\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1289db-af5d-4183-983c-a8423516ba50",
   "metadata": {},
   "source": [
    "## test f1 score will likely be close to .767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "ac9718ca-b4dc-4b31-bea9-901019ff3392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv1d(1, 256, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "  (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (conv3): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "  (conv4): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(2,))\n",
       "  (conv5): Conv1d(256, 1, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (fc1): Linear(in_features=2, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (norm5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (avg1): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "  (avg2): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))\n",
       "  (avg3): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(1,))\n",
       ")"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Net()\n",
    "model.load_state_dict(torch.load('best_model_4.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9f70be20-e9e3-42f8-8372-27ce395113a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>preg</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>6</td>\n",
       "      <td>134</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>130</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.542</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  preg  plasma  pressure  skin  insulin   bmi  pedigree  age\n",
       "0    171     6     134        70    23      130  35.4     0.542   29"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = pd.read_csv(\"pima-indians-diabetes_eval_no_class.csv\")\n",
    "eval.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227fdf50-50ed-47e9-9049-dac891560789",
   "metadata": {},
   "source": [
    "## blind test diabetes predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f6d6b960-a60c-4378-9bc7-402e6f6637b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = eval[cols_to_include].values\n",
    "model.eval()\n",
    "Z_pred = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        X = X_test[4*i:4*(i+1)]\n",
    "        X = torch.tensor(X, dtype=torch.float32).unsqueeze(1) # add channel dim\n",
    "        # print(np.array(torch.argmax((nnF.softmax(model(X), dim=1)),dim=1)))\n",
    "        Z = np.array(torch.argmax((nnF.softmax(model(X), dim=1)),dim=1))\n",
    "        Z_pred.extend(list(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "763b031c-2135-46d3-a80f-d47b3c4922ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "a7c07ea2-25c5-4d18-b111-ad5e20f99fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 231)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval),len(Z_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f12bbb3c-cf37-40e5-a8e9-e4a47689cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval[\"class\"] = Z_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "98cd0b5d-ab9c-407a-b457-d2e2455f2511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>preg</th>\n",
       "      <th>plasma</th>\n",
       "      <th>pressure</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>6</td>\n",
       "      <td>134</td>\n",
       "      <td>70</td>\n",
       "      <td>23</td>\n",
       "      <td>130</td>\n",
       "      <td>35.4</td>\n",
       "      <td>0.542</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>696</td>\n",
       "      <td>3</td>\n",
       "      <td>169</td>\n",
       "      <td>74</td>\n",
       "      <td>19</td>\n",
       "      <td>125</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.268</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>442</td>\n",
       "      <td>4</td>\n",
       "      <td>117</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>120</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>638</td>\n",
       "      <td>7</td>\n",
       "      <td>97</td>\n",
       "      <td>76</td>\n",
       "      <td>32</td>\n",
       "      <td>91</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.871</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>393</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>72</td>\n",
       "      <td>12</td>\n",
       "      <td>87</td>\n",
       "      <td>22.1</td>\n",
       "      <td>0.463</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>257</td>\n",
       "      <td>2</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>28.7</td>\n",
       "      <td>0.092</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>206</td>\n",
       "      <td>8</td>\n",
       "      <td>196</td>\n",
       "      <td>76</td>\n",
       "      <td>29</td>\n",
       "      <td>280</td>\n",
       "      <td>37.5</td>\n",
       "      <td>0.605</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>390</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>196</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>78</td>\n",
       "      <td>32</td>\n",
       "      <td>265</td>\n",
       "      <td>46.5</td>\n",
       "      <td>1.159</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.703</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  preg  plasma  pressure  skin  insulin   bmi  pedigree  age  class\n",
       "0      171     6     134        70    23      130  35.4     0.542   29      0\n",
       "1      696     3     169        74    19      125  29.9     0.268   31      1\n",
       "2      442     4     117        64    27      120  33.2     0.230   24      0\n",
       "3      638     7      97        76    32       91  40.9     0.871   32      0\n",
       "4      393     4     116        72    12       87  22.1     0.463   37      0\n",
       "..     ...   ...     ...       ...   ...      ...   ...       ...  ...    ...\n",
       "226    257     2     114        68    22        0  28.7     0.092   25      0\n",
       "227    206     8     196        76    29      280  37.5     0.605   57      1\n",
       "228    390     1     100        66    29      196  32.0     0.444   42      0\n",
       "229    487     0     173        78    32      265  46.5     1.159   58      1\n",
       "230    138     0     129        80     0        0  31.2     0.703   29      1\n",
       "\n",
       "[231 rows x 10 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e3ee7e-d7f6-4d2f-b0cf-27aea8a72a6d",
   "metadata": {},
   "source": [
    "## save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5d1d74ce-004e-4ba7-a04f-32b9a4475a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a148e-6bca-45c4-ac90-a0f321a975d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
